{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a14ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ite\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec07da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m input_size \u001b[38;5;241m=\u001b[39m ppg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Initializing model and optimizers\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m model \u001b[38;5;241m=\u001b[39m Net(input_size, input_size, emb_dim)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[0;32m     78\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Conversion to tensors\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple 5 layer perceptron autoencoder. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size=45, hidden_size=45, bottleneck_size=20):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bottleneck_size = bottleneck_size\n",
    "\n",
    "        # ENCODER\n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(self.hidden_size, self.bottleneck_size)\n",
    "\n",
    "        # DECODER\n",
    "        self.fc4 = torch.nn.Linear(self.bottleneck_size, self.hidden_size)\n",
    "        self.fc5 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc6 = torch.nn.Linear(self.hidden_size, self.input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = F.leaky_relu(self.fc1(x), 0.1)\n",
    "        enc = F.leaky_relu(self.fc2(enc), 0.1)\n",
    "        enc = F.leaky_relu(self.fc3(enc), 0.1)\n",
    "\n",
    "        dec = F.leaky_relu(self.fc4(enc), 0.1)\n",
    "        dec = F.leaky_relu(self.fc5(dec), 0.1)\n",
    "        dec = F.leaky_relu(self.fc6(dec), 0.1)\n",
    "        return enc, dec\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\n",
    "#     \"--ppg_path\",\n",
    "#     help=\"Path of Normalized PPG numpy array with each element representing the PPG signal\",\n",
    "#     default=\"../data/flatten_ppg.npy\",\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     \"-label_path\",\n",
    "#     help=\"Path of PPG numpy array with each element representing the PPG signal\",\n",
    "#     default=\"../data/flatten_sbp.npy\",\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\"-ite_path\", help=\"Path to the ite-repo\", default=None)\n",
    "# parser.add_argument(\n",
    "#     \"-emb_dim\", help=\"size of the bottleneck layer embeddings\", default=20\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     \"-neighbors\",\n",
    "#     help=\"neighbor parameter for the estimation of mutual information. Higher values reduce the variance but might introduce a bias\",\n",
    "#     default=100,\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\"-device\", help=\"GPU or CPU\", default=\"cuda:0\")\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Loading the ite-library for mutual information estimation. Check https://bitbucket.org/szzoli/ite-in-python/\n",
    "# sys.path.insert(\n",
    "#     1,\n",
    "#     \"/home/t-surilmehta/home/szzoli-ite-in-python-44a8f15e2dc9/szzoli-ite-in-python-44a8f15e2dc9\",\n",
    "# )\n",
    "\n",
    "# Loading data and parameters\n",
    "ppg = test_4\n",
    "label = test_sbp\n",
    "emb_dim =20\n",
    "# device = args.device\n",
    "input_size = ppg.shape[1]\n",
    "\n",
    "# Initializing model and optimizers\n",
    "model = Net(input_size, input_size, emb_dim).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Conversion to tensors\n",
    "X, Y = torch.FloatTensor(ppg), torch.FloatTensor(label)\n",
    "train_dataset = TensorDataset(X, Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "epochs = 10000\n",
    "from tqdm import trange\n",
    "# Training+Validation loop\n",
    "for epoch in trange(epochs + 1):\n",
    "    optim.zero_grad()\n",
    "    train_loss, test_loss = 0, 0\n",
    "    model.train()\n",
    "    for inp, label in train_loader:\n",
    "        inp, label = inp.to(device), label.to(device)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            enc, out = model(inp)\n",
    "            loss = F.mse_loss(out, inp)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    y, encodings = [], []\n",
    "    for inp, label in train_loader:\n",
    "        inp, label = inp.to(device), label.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            enc, out = model(inp)\n",
    "            loss = F.mse_loss(out, inp)\n",
    "            encodings.extend(enc.cpu().detach().numpy())\n",
    "            y.extend(label.cpu().detach().numpy())\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    train_loss, test_loss = (\n",
    "        round(train_loss / len(train_loader), 3),\n",
    "        round(test_loss / len(train_loader), 3),\n",
    "    )\n",
    "\n",
    "    # Logging the loss values and estimating mutual information.\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch:{epoch} Train_Loss:{train_loss} Test_Loss:{test_loss}\")\n",
    "\n",
    "    if train_loss < 0.1 or test_loss < 0.1 and epoch % 5 == 0:\n",
    "        print(f\"Epoch:{epoch} Train_Loss:{train_loss} Test_Loss:{test_loss}\")\n",
    "        encodings, y = np.asarray(encodings), np.asarray(y).reshape(-1, 1)\n",
    "        co = ite.cost.MIShannon_DKL(\n",
    "            mult=True, kl_co_name=\"BDKL_KnnK\", kl_co_pars={\"k\": 100}\n",
    "        )\n",
    "        # emb_dim = 20\n",
    "        print(encodings.shape, y.shape)\n",
    "        val = co.estimation(np.hstack((encodings, y)), [emb_dim, 1])\n",
    "        print(f\"MI value:{val}\")\n",
    "        co_HY = ite.cost.BHShannon_KnnK(mult=True, k=100)\n",
    "        H_Y = co_HY.estimation(y.reshape(-1,1))\n",
    "        print(f\"Entropy of target (H_Y): {H_Y}\")\n",
    "        info_fraction = val / H_Y\n",
    "        print(f\"Info-Fraction: {info_fraction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da466b",
   "metadata": {},
   "source": [
    "## load  input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5780d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38110, 1250), (38110,), (111600,), (111600, 1250), (111600,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_2.npy\")[:,1]\n",
    "test_sbp_2 = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_sbp_2.npy\")\n",
    "test_dbp = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_dbp.npy\")\n",
    "test_4 = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_4.npy\").squeeze()\n",
    "test_sbp = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_sbp.npy\")\n",
    "test_2.shape,test_sbp_2.shape,test_dbp.shape,test_4.shape,test_sbp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6254eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sbp_2labels = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_sbp_2labels.npy\")\n",
    "test_sbp_4labels = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\processed\\\\BP_npy\\\\PulseDB\\\\test_sbp_4labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3374cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 2,\n",
       "       0, 1, 3, 1, 1, 3, 3, 1, 1, 1, 3, 3, 3, 3, 2, 3, 1, 2, 3, 2, 2, 1,\n",
       "       3, 1, 3, 1, 3, 2, 3, 3, 3, 1, 2, 2, 2, 3, 3, 1, 2, 3, 2, 1, 3, 1,\n",
       "       3, 3, 1, 3, 3, 1, 2, 3, 2, 1, 3, 2, 2, 3, 3, 2, 3, 1, 2, 2, 2, 3,\n",
       "       2, 2, 3, 2, 1, 2, 1, 1, 2, 3, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sbp_4labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d9689c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83.05106629,  81.75012088,  80.38314718,  79.07587822,\n",
       "        77.08756172,  75.06585372,  73.38349937,  71.82009373,\n",
       "        70.74982242,  69.65830052,  68.60469233,  68.44008512,\n",
       "        68.22482364,  67.37617673,  68.01488514,  68.7227993 ,\n",
       "        68.41480079,  68.9993008 ,  68.99467477,  68.44390371,\n",
       "        68.41623601,  68.39353164,  68.45823385,  67.83598993,\n",
       "        67.18228907,  67.2565631 ,  67.20980974,  67.07671381,\n",
       "        67.56650494,  69.59775776,  73.11195278,  77.97092736,\n",
       "        84.60065154,  92.76061522, 101.99761091, 111.38650746,\n",
       "       120.59963303, 128.9817073 , 135.31293323, 139.8897224 ,\n",
       "       142.64108908, 142.95101796, 140.75307725, 136.91826539,\n",
       "       132.10592029, 125.94105043, 119.65114131, 114.07136866,\n",
       "       108.0501885 , 102.65635919,  98.40514212,  94.64634219,\n",
       "        92.44722388,  90.79880825,  89.25317731,  88.70422841,\n",
       "        88.22872354,  87.46775458,  86.11075563,  84.59287798,\n",
       "        83.45771371,  81.74131707,  80.0203382 ,  78.50928348,\n",
       "        76.96427764,  76.33697732,  76.2927377 ,  76.70110139,\n",
       "        77.41364312,  78.10296053,  79.24038812,  80.66107818,\n",
       "        81.90871727,  82.99297141,  83.90809264,  84.08101995,\n",
       "        84.08988888,  83.91934282,  82.98136814,  81.97159977,\n",
       "        80.57891568,  78.68061245,  76.91908061,  75.04930043,\n",
       "        72.95659161,  71.74340612,  70.54005456,  69.08912318,\n",
       "        68.73204511,  67.98860572,  67.96799045,  68.40067589,\n",
       "        67.59307108,  67.93132786,  68.57698694,  68.31123411,\n",
       "        68.43514852,  68.90003023,  68.72063157,  68.35916612])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2[1,0,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33f5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet1d import ResNet1D\n",
    "config = {\n",
    "    \"network\":{\n",
    "        \"in_channels\":1,\n",
    "        \"base_filters\":64,\n",
    "        \"kernel_size\":3,\n",
    "        \"stride\":1,\n",
    "        \"groups\":1,\n",
    "        \"n_block\":5,\n",
    "        \"n_classes\":2,\n",
    "    },\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\":100,\n",
    "    \"log_interval\":100,\n",
    "    \"input_shape\":[1,1250],\n",
    "    \"output_path\": \"..\\\\outputs\\\\resnet\\\\0228\",\n",
    "    \"ppg\":10    \n",
    "          }\n",
    "model = ResNet1D(**config[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93391c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45464fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsa\\AppData\\Local\\Temp\\ipykernel_39216\\1154037463.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('..\\\\outputs\\\\resnet\\\\0228\\\\best.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet1D(\n",
       "  (first_block_conv): MyConv1dPadSame(\n",
       "    (conv): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (first_block_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (first_block_relu): ReLU()\n",
       "  (basicblock_list): ModuleList(\n",
       "    (0-3): 4 x BasicBlock(\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (do1): Dropout(p=0.5, inplace=False)\n",
       "      (conv1): MyConv1dPadSame(\n",
       "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (do2): Dropout(p=0.5, inplace=False)\n",
       "      (conv2): MyConv1dPadSame(\n",
       "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (max_pool): MyMaxPool1dPadSame(\n",
       "        (max_pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (do1): Dropout(p=0.5, inplace=False)\n",
       "      (conv1): MyConv1dPadSame(\n",
       "        (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (do2): Dropout(p=0.5, inplace=False)\n",
       "      (conv2): MyConv1dPadSame(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (max_pool): MyMaxPool1dPadSame(\n",
       "        (max_pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final_relu): ReLU(inplace=True)\n",
       "  (dense): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('..\\\\outputs\\\\resnet\\\\0228\\\\best.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938f3deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x1725ca9c1f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    outputs['features'] = output\n",
    "model.final_relu.register_forward_hook(hook_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db41fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# encodings_scaled = scaler.fit_transform(encodings)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "# encodings_reduced = pca.fit_transform(encodings_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71d974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a19c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [00:05<00:00, 218.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38110, 21)\n",
      "MI value:10.338875400195587\n",
      "Entropy of target (H_Y): 3.979911211307363\n",
      "Info-Fraction: 2.597765339794946\n"
     ]
    }
   ],
   "source": [
    "X_ = torch.from_numpy(test_2).float().unsqueeze(1).to(device)\n",
    "y_ = torch.from_numpy(test_sbp_2).float().to(device)\n",
    "dataset = TensorDataset(X_,y_)\n",
    "loader = DataLoader(dataset, batch_size=32)\n",
    "encodings = []\n",
    "y_out = []\n",
    "for X,y in tqdm(loader):\n",
    "    _ = model(X)\n",
    "    out = outputs['features'].clone()\n",
    "    # print(out.shape)\n",
    "    out = out.mean(-1)\n",
    "    out = out.flatten(start_dim=1).cpu().detach().numpy()\n",
    "\n",
    "    \n",
    "    # print(out.shape)\n",
    "    encodings.append(out)\n",
    "    y_out.extend(y.cpu().detach().numpy())\n",
    "encodings= np.concatenate(encodings)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encodings_scaled = scaler.fit_transform(encodings)\n",
    "pca = PCA(n_components=20)\n",
    "encodings_reduced = pca.fit_transform(encodings_scaled)\n",
    "y = np.array(y_out).reshape(-1, 1)\n",
    "co = ite.cost.MIShannon_DKL(\n",
    "    mult=True, kl_co_name=\"BDKL_KnnK\", kl_co_pars={\"k\": 10}\n",
    ")\n",
    "\n",
    "\n",
    "emb_dim =20\n",
    "stack = np.hstack((encodings_reduced, y))\n",
    "print(stack.shape)\n",
    "val = co.estimation(stack, [emb_dim, 1])\n",
    "print(f\"MI value:{val}\")\n",
    "\n",
    "# Y のみでエントロピー推定\n",
    "co_HY = ite.cost.BHShannon_KnnK(mult=True, k=10)\n",
    "H_Y = co_HY.estimation(y.reshape(-1,1))\n",
    "print(f\"Entropy of target (H_Y): {H_Y}\")\n",
    "info_fraction = val / H_Y\n",
    "print(f\"Info-Fraction: {info_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fa7aef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ite.cost' has no attribute 'HShannon_DKL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m co_entropy \u001b[38;5;241m=\u001b[39m \u001b[43mite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHShannon_DKL\u001b[49m(mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, kl_co_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBDKL_KnnK\u001b[39m\u001b[38;5;124m\"\u001b[39m, kl_co_pars\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m})\n\u001b[0;32m      2\u001b[0m H_Y \u001b[38;5;241m=\u001b[39m co_entropy\u001b[38;5;241m.\u001b[39mestimation(y)\n\u001b[0;32m      3\u001b[0m H_Y\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'ite.cost' has no attribute 'HShannon_DKL'"
     ]
    }
   ],
   "source": [
    "co_entropy = ite.cost.HShannon_DKL(mult=False, kl_co_name=\"BDKL_KnnK\", kl_co_pars={\"k\": 20})\n",
    "H_Y = co_entropy.estimation(y)\n",
    "H_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epochs\n",
    "fo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75457e",
   "metadata": {},
   "source": [
    "# features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6731dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87507, 102), (6974, 7))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\results\\\\ppg_features_pulsedb_test_min180.csv',index_col=0)\n",
    "\n",
    "# target = pd.read_csv('F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\results\\\\target.csv',index_col=0)\n",
    "# features.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by signal_index\n",
    "# features = features.sort_values(\"signal_index\")\n",
    "# target = target.loc[features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aeb05af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_DBP</th>\n",
       "      <th>err_SBP</th>\n",
       "      <th>abs_err_DBP</th>\n",
       "      <th>abs_err_SBP</th>\n",
       "      <th>target_SBP</th>\n",
       "      <th>target_DBP</th>\n",
       "      <th>signal_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.893147</td>\n",
       "      <td>-9.505203</td>\n",
       "      <td>6.893147</td>\n",
       "      <td>9.505203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.536797</td>\n",
       "      <td>-5.235329</td>\n",
       "      <td>5.536797</td>\n",
       "      <td>5.235329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-18.116745</td>\n",
       "      <td>6.519360</td>\n",
       "      <td>18.116745</td>\n",
       "      <td>6.519360</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36.884052</td>\n",
       "      <td>-19.033958</td>\n",
       "      <td>36.884052</td>\n",
       "      <td>19.033958</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-21.217396</td>\n",
       "      <td>-3.074295</td>\n",
       "      <td>21.217396</td>\n",
       "      <td>3.074295</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     err_DBP    err_SBP  abs_err_DBP  abs_err_SBP  target_SBP  target_DBP  \\\n",
       "0  -6.893147  -9.505203     6.893147     9.505203           1           1   \n",
       "1  -5.536797  -5.235329     5.536797     5.235329           1           1   \n",
       "2 -18.116745   6.519360    18.116745     6.519360           1           2   \n",
       "3 -36.884052 -19.033958    36.884052    19.033958           2           2   \n",
       "4 -21.217396  -3.074295    21.217396     3.074295           0           2   \n",
       "\n",
       "   signal_index  \n",
       "0             0  \n",
       "1             1  \n",
       "2             2  \n",
       "3             3  \n",
       "4             4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "679bffda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87507, 98), (87507, 1))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove signal_index\n",
    "y = features['sbp'].values.reshape(-1,1)\n",
    "X = features.drop(columns=[\"signal_index\",\"subject\",\"sbp\",\"dbp\"])\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea7ec442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tc', 'Ts', 'Td', 'Tsteepest', 'Steepest', 'TNegSteepest',\n",
       "       'NegSteepest', 'TdiaRise', 'DiaRise', 'SteepDiaRise', 'TSystoDiaRise',\n",
       "       'TdiaToEnd', 'Ratio', 'Ts_norm', 'Td_norm', 'Tsteepest_norm',\n",
       "       'TNegSteepest_norm', 'TdiaRise_norm', 'TSystoDiaRise_norm',\n",
       "       'TdiaToEnd_norm', 'SW25', 'SW25_norm', 'DW25', 'DW25_norm', 'SWaddDW25',\n",
       "       'SWaddDW25_norm', 'DWdivSW25', 'SW50', 'SW50_norm', 'DW50', 'DW50_norm',\n",
       "       'SWaddDW50', 'SWaddDW50_norm', 'DWdivSW50', 'SW75', 'SW75_norm', 'DW75',\n",
       "       'DW75_norm', 'SWaddDW75', 'SWaddDW75_norm', 'DWdivSW75', 'S1', 'S2',\n",
       "       'S3', 'S4', 'AUCsys', 'AUCdia', 'S1_norm', 'S2_norm', 'S3_norm',\n",
       "       'S4_norm', 'AUCsys_norm', 'AUCdia_norm', 'SQI_skew', 'SQI_kurtosis',\n",
       "       'apg_a', 'apg_b', 'apg_c', 'apg_d', 'apg_e', 'ppg_a', 'ppg_b', 'ppg_c',\n",
       "       'ppg_d', 'ppg_e', 'ratio_apg_b', 'ratio_apg_c', 'ratio_apg_d',\n",
       "       'ratio_apg_e', 'ratio_ppg_b', 'ratio_ppg_c', 'ratio_ppg_d',\n",
       "       'ratio_ppg_e', 'T_a', 'T_b', 'T_c', 'T_d', 'T_e', 'T_a_norm',\n",
       "       'T_b_norm', 'T_c_norm', 'T_d_norm', 'T_e_norm', 'T_peak_a', 'T_peak_b',\n",
       "       'T_peak_c', 'T_peak_d', 'T_peak_e', 'T_peak_a_norm', 'T_peak_b_norm',\n",
       "       'T_peak_c_norm', 'T_peak_d_norm', 'T_peak_e_norm', 'AI', 'bd', 'bcda',\n",
       "       'sdoo', 'signal_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb60f932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [2],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec7caee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan to 0\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1aa8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebbe57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# # encodings_scaled = scaler.fit_transform(encodings)\n",
    "\n",
    "# pca = PCA(n_components=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad288076",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "encodings_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "encodings_reduced = pca.fit_transform(encodings_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c4624c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c7d8804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490.59446872250106,\n",
       " -25.76702033256711,\n",
       " -3.605208436782023e-18,\n",
       " 2.1940844031446582)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings_reduced.max(),encodings_reduced.min(),encodings_reduced.mean(),encodings_reduced.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c008f11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1943,    0, 2617,    0, 2414], dtype=int64),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. ]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(y,bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd6a1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87507, 20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbbea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.657210370767604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LDDP_entropy(x, bins=100):\n",
    "    \"\"\"\n",
    "    LDDPによる連続変数のエントロピー推定\n",
    "    x: 1次元連続データ\n",
    "    bins: 離散化ビンの数\n",
    "    \"\"\"\n",
    "    hist, bin_edges = np.histogram(x, bins=bins, density=True)\n",
    "    # 0の要素を除く\n",
    "    hist = hist[hist > 0]\n",
    "    H = -np.sum(hist * np.log(hist))  # 微分エントロピーに近似\n",
    "    return H\n",
    "print(\"bins\",int(np.sqrt(len(y))))\n",
    "H_y = LDDP_entropy(y, bins=int(np.sqrt(len(y))))\n",
    "H_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81b35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI value:6.975802441620895\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LDDP_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 31\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMI value:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# emb_dim =20\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# stack = np.hstack((encodings_reduced, y_scaled))\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(stack.shape)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Y のみでエントロピー推定\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m H_Y \u001b[38;5;241m=\u001b[39m \u001b[43mLDDP_entropy\u001b[49m(y_scaled, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mlen\u001b[39m(y))))\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# co_HY = ite.cost.BHShannon_KnnK(mult=True, k=100)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# H_Y = co_HY.estimation(y_scaled.reshape(-1,1))\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntropy of target (H_Y): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH_Y\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LDDP_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('F:\\\\minowa\\\\BloodPressureEstimation\\\\data\\\\results\\\\ppg_features_pulsedb_test_all.csv',index_col=0)\n",
    "\n",
    "y = features['sbp'].values.reshape(-1,1)\n",
    "X = features.drop(columns=[\"signal_index\",\"subject\",\"sbp\",\"dbp\"])\n",
    "X = X.fillna(0)\n",
    "scaler = StandardScaler()\n",
    "scalery = StandardScaler()\n",
    "encodings_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scalery.fit_transform(y)\n",
    "pca = PCA(n_components=20)\n",
    "encodings_reduced = pca.fit_transform(encodings_scaled)\n",
    "emb_dim =20\n",
    "co = ite.cost.MIShannon_DKL(\n",
    "    mult=True, kl_co_name=\"BDKL_KnnK\", kl_co_pars={\"k\": 100}\n",
    ")\n",
    "# co = ite.cost.MIShannon_HS(\n",
    "#     mult=True, shannon_co_name=\"BHShannon_KnnK\", shannon_co_pars={\"k\": 10}\n",
    "# )\n",
    "# stack = np.hstack((encodings_reduced, y_scaled))\n",
    "# print(stack.shape)\n",
    "\n",
    "val = co.estimation(np.hstack((encodings_reduced, y_scaled)), [emb_dim, 1])\n",
    "print(f\"MI value:{val}\")\n",
    "# emb_dim =20\n",
    "# stack = np.hstack((encodings_reduced, y_scaled))\n",
    "# print(stack.shape)\n",
    "# val = co.estimation(stack, [emb_dim,1])\n",
    "# print(f\"MI value:{val}\")\n",
    "\n",
    "# Y のみでエントロピー推定\n",
    "H_Y = LDDP_entropy(y_scaled, bins=int(np.sqrt(len(y))))\n",
    "# co_HY = ite.cost.BHShannon_KnnK(mult=True, k=100)\n",
    "# H_Y = co_HY.estimation(y_scaled.reshape(-1,1))\n",
    "print(f\"Entropy of target (H_Y): {H_Y}\")\n",
    "info_fraction = val / H_Y\n",
    "print(f\"Info-Fraction: {info_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a9b359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of target (H_Y): 36.4072130650931\n",
      "Info-Fraction: 0.19160495556605045\n"
     ]
    }
   ],
   "source": [
    "H_Y = LDDP_entropy(y_scaled, bins=int(np.sqrt(len(y))))\n",
    "# co_HY = ite.cost.BHShannon_KnnK(mult=True, k=100)\n",
    "# H_Y = co_HY.estimation(y_scaled.reshape(-1,1))\n",
    "print(f\"Entropy of target (H_Y): {H_Y}\")\n",
    "info_fraction = val / H_Y\n",
    "print(f\"Info-Fraction: {info_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32f245b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90289, 98)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "115084ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tc', 'Ts', 'Td', 'Tsteepest', 'Steepest', 'TNegSteepest',\n",
       "       'NegSteepest', 'TdiaRise', 'DiaRise', 'SteepDiaRise', 'TSystoDiaRise',\n",
       "       'TdiaToEnd', 'Ratio', 'Ts_norm', 'Td_norm', 'Tsteepest_norm',\n",
       "       'TNegSteepest_norm', 'TdiaRise_norm', 'TSystoDiaRise_norm',\n",
       "       'TdiaToEnd_norm', 'SW25', 'SW25_norm', 'DW25', 'DW25_norm', 'SWaddDW25',\n",
       "       'SWaddDW25_norm', 'DWdivSW25', 'SW50', 'SW50_norm', 'DW50', 'DW50_norm',\n",
       "       'SWaddDW50', 'SWaddDW50_norm', 'DWdivSW50', 'SW75', 'SW75_norm', 'DW75',\n",
       "       'DW75_norm', 'SWaddDW75', 'SWaddDW75_norm', 'DWdivSW75', 'S1', 'S2',\n",
       "       'S3', 'S4', 'AUCsys', 'AUCdia', 'S1_norm', 'S2_norm', 'S3_norm',\n",
       "       'S4_norm', 'AUCsys_norm', 'AUCdia_norm', 'SQI_skew', 'SQI_kurtosis',\n",
       "       'apg_a', 'apg_b', 'apg_c', 'apg_d', 'apg_e', 'ppg_a', 'ppg_b', 'ppg_c',\n",
       "       'ppg_d', 'ppg_e', 'ratio_apg_b', 'ratio_apg_c', 'ratio_apg_d',\n",
       "       'ratio_apg_e', 'ratio_ppg_b', 'ratio_ppg_c', 'ratio_ppg_d',\n",
       "       'ratio_ppg_e', 'T_a', 'T_b', 'T_c', 'T_d', 'T_e', 'T_a_norm',\n",
       "       'T_b_norm', 'T_c_norm', 'T_d_norm', 'T_e_norm', 'T_peak_a', 'T_peak_b',\n",
       "       'T_peak_c', 'T_peak_d', 'T_peak_e', 'T_peak_a_norm', 'T_peak_b_norm',\n",
       "       'T_peak_c_norm', 'T_peak_d_norm', 'T_peak_e_norm', 'AI', 'bd', 'bcda',\n",
       "       'sdoo', 'cycle_zero'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c866acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90289, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7914c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import normi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcae35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NMI Estimation: 100%|██████████| 210/210 [00:28<00:00,  7.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NormalizedMI()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NormalizedMI</label><div class=\"sk-toggleable__content\"><pre>NormalizedMI()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NormalizedMI()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmi = normi.NormalizedMI()\n",
    "nmi.fit(np.hstack((encodings_reduced, y_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d65211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.24950743, 0.14418986, 0.23071748, 0.30415178,\n",
       "        0.09181826, 0.15440525, 0.08853288, 0.10607724, 0.1059909 ,\n",
       "        0.12598128, 0.05952238, 0.10711379, 0.14692663, 0.08795783,\n",
       "        0.10686127, 0.05558863, 0.10695801, 0.08346583, 0.06594345,\n",
       "        0.06384538],\n",
       "       [0.24950743, 1.        , 0.06369214, 0.08578973, 0.13329494,\n",
       "        0.14154514, 0.08904765, 0.0823105 , 0.18751399, 0.07603466,\n",
       "        0.19314375, 0.05038646, 0.06580538, 0.14116976, 0.08531182,\n",
       "        0.09553049, 0.07270253, 0.059911  , 0.05306916, 0.05775511,\n",
       "        0.03015064],\n",
       "       [0.14418986, 0.06369214, 1.        , 0.04585241, 0.21555431,\n",
       "        0.26092038, 0.61210923, 0.04095515, 0.04191576, 0.0552125 ,\n",
       "        0.0756094 , 0.07093676, 0.08569184, 0.04580937, 0.05835063,\n",
       "        0.03108411, 0.06896625, 0.0627241 , 0.08297298, 0.06419235,\n",
       "        0.05096265],\n",
       "       [0.23071748, 0.08578973, 0.04585241, 1.        , 0.21807554,\n",
       "        0.05132776, 0.06656374, 0.02884584, 0.05544115, 0.04914095,\n",
       "        0.06246343, 0.05035835, 0.04399486, 0.04722639, 0.04464413,\n",
       "        0.07949617, 0.04352641, 0.05730619, 0.06200476, 0.07797615,\n",
       "        0.02501729],\n",
       "       [0.30415178, 0.13329494, 0.21555431, 0.21807554, 1.        ,\n",
       "        0.2116648 , 0.19344992, 0.05242697, 0.04668397, 0.06331285,\n",
       "        0.07828188, 0.07051887, 0.08592532, 0.09792489, 0.0298802 ,\n",
       "        0.06231988, 0.07709105, 0.08627066, 0.06089147, 0.04143598,\n",
       "        0.03432365],\n",
       "       [0.09181826, 0.14154514, 0.26092038, 0.05132776, 0.2116648 ,\n",
       "        1.        , 0.43554519, 0.03107615, 0.0828739 , 0.06272027,\n",
       "        0.06537729, 0.05704346, 0.05967259, 0.07165568, 0.03481797,\n",
       "        0.02779956, 0.05028037, 0.0474214 , 0.0364789 , 0.02502981,\n",
       "        0.01804427],\n",
       "       [0.15440525, 0.08904765, 0.61210923, 0.06656374, 0.19344992,\n",
       "        0.43554519, 1.        , 0.04276127, 0.04130191, 0.07602913,\n",
       "        0.10892755, 0.05689012, 0.11435418, 0.0622515 , 0.04670395,\n",
       "        0.04126147, 0.06321381, 0.05009787, 0.06506265, 0.04044558,\n",
       "        0.04645585],\n",
       "       [0.08853288, 0.0823105 , 0.04095515, 0.02884584, 0.05242697,\n",
       "        0.03107615, 0.04276127, 1.        , 0.04094401, 0.098572  ,\n",
       "        0.0722519 , 0.0275333 , 0.04887539, 0.08481713, 0.03830292,\n",
       "        0.0337732 , 0.02396396, 0.03864523, 0.03201418, 0.02251868,\n",
       "        0.02910921],\n",
       "       [0.10607724, 0.18751399, 0.04191576, 0.05544115, 0.04668397,\n",
       "        0.0828739 , 0.04130191, 0.04094401, 1.        , 0.03578767,\n",
       "        0.05292564, 0.03900171, 0.03941483, 0.03763539, 0.03542321,\n",
       "        0.03836557, 0.05059143, 0.03195749, 0.03600834, 0.03092659,\n",
       "        0.02309233],\n",
       "       [0.1059909 , 0.07603466, 0.0552125 , 0.04914095, 0.06331285,\n",
       "        0.06272027, 0.07602913, 0.098572  , 0.03578767, 1.        ,\n",
       "        0.0390999 , 0.02533126, 0.06112764, 0.06586586, 0.0499704 ,\n",
       "        0.04522021, 0.03815286, 0.04012534, 0.02867443, 0.06310791,\n",
       "        0.01603734],\n",
       "       [0.12598128, 0.19314375, 0.0756094 , 0.06246343, 0.07828188,\n",
       "        0.06537729, 0.10892755, 0.0722519 , 0.05292564, 0.0390999 ,\n",
       "        1.        , 0.06170757, 0.11587679, 0.20904904, 0.04683196,\n",
       "        0.0612419 , 0.04166794, 0.03491709, 0.04727875, 0.02249684,\n",
       "        0.0212297 ],\n",
       "       [0.05952238, 0.05038646, 0.07093676, 0.05035835, 0.07051887,\n",
       "        0.05704346, 0.05689012, 0.0275333 , 0.03900171, 0.02533126,\n",
       "        0.06170757, 1.        , 0.11156981, 0.03695041, 0.01994622,\n",
       "        0.02806905, 0.02777859, 0.02468223, 0.02394697, 0.02214658,\n",
       "        0.01928341],\n",
       "       [0.10711379, 0.06580538, 0.08569184, 0.04399486, 0.08592532,\n",
       "        0.05967259, 0.11435418, 0.04887539, 0.03941483, 0.06112764,\n",
       "        0.11587679, 0.11156981, 1.        , 0.12117552, 0.03446006,\n",
       "        0.03636244, 0.01984887, 0.03158224, 0.028416  , 0.02838234,\n",
       "        0.01335139],\n",
       "       [0.14692663, 0.14116976, 0.04580937, 0.04722639, 0.09792489,\n",
       "        0.07165568, 0.0622515 , 0.08481713, 0.03763539, 0.06586586,\n",
       "        0.20904904, 0.03695041, 0.12117552, 1.        , 0.06821042,\n",
       "        0.07815017, 0.03738478, 0.06413708, 0.05570349, 0.03509306,\n",
       "        0.03143824],\n",
       "       [0.08795783, 0.08531182, 0.05835063, 0.04464413, 0.0298802 ,\n",
       "        0.03481797, 0.04670395, 0.03830292, 0.03542321, 0.0499704 ,\n",
       "        0.04683196, 0.01994622, 0.03446006, 0.06821042, 1.        ,\n",
       "        0.09137456, 0.02542464, 0.04527387, 0.07813869, 0.12671017,\n",
       "        0.02805134],\n",
       "       [0.10686127, 0.09553049, 0.03108411, 0.07949617, 0.06231988,\n",
       "        0.02779956, 0.04126147, 0.0337732 , 0.03836557, 0.04522021,\n",
       "        0.0612419 , 0.02806905, 0.03636244, 0.07815017, 0.09137456,\n",
       "        1.        , 0.03737405, 0.04828949, 0.05435232, 0.07623588,\n",
       "        0.01597218],\n",
       "       [0.05558863, 0.07270253, 0.06896625, 0.04352641, 0.07709105,\n",
       "        0.05028037, 0.06321381, 0.02396396, 0.05059143, 0.03815286,\n",
       "        0.04166794, 0.02777859, 0.01984887, 0.03738478, 0.02542464,\n",
       "        0.03737405, 1.        , 0.09164339, 0.05038404, 0.03375733,\n",
       "        0.02302654],\n",
       "       [0.10695801, 0.059911  , 0.0627241 , 0.05730619, 0.08627066,\n",
       "        0.0474214 , 0.05009787, 0.03864523, 0.03195749, 0.04012534,\n",
       "        0.03491709, 0.02468223, 0.03158224, 0.06413708, 0.04527387,\n",
       "        0.04828949, 0.09164339, 1.        , 0.06512733, 0.03348796,\n",
       "        0.02645756],\n",
       "       [0.08346583, 0.05306916, 0.08297298, 0.06200476, 0.06089147,\n",
       "        0.0364789 , 0.06506265, 0.03201418, 0.03600834, 0.02867443,\n",
       "        0.04727875, 0.02394697, 0.028416  , 0.05570349, 0.07813869,\n",
       "        0.05435232, 0.05038404, 0.06512733, 1.        , 0.07829878,\n",
       "        0.02967488],\n",
       "       [0.06594345, 0.05775511, 0.06419235, 0.07797615, 0.04143598,\n",
       "        0.02502981, 0.04044558, 0.02251868, 0.03092659, 0.06310791,\n",
       "        0.02249684, 0.02214658, 0.02838234, 0.03509306, 0.12671017,\n",
       "        0.07623588, 0.03375733, 0.03348796, 0.07829878, 1.        ,\n",
       "        0.01473361],\n",
       "       [0.06384538, 0.03015064, 0.05096265, 0.02501729, 0.03432365,\n",
       "        0.01804427, 0.04645585, 0.02910921, 0.02309233, 0.01603734,\n",
       "        0.0212297 , 0.01928341, 0.01335139, 0.03143824, 0.02805134,\n",
       "        0.01597218, 0.02302654, 0.02645756, 0.02967488, 0.01473361,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmi.mi_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e5cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.special import digamma\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def mutual_information_ksg_full(X, y, k=5):\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    n, dx = X.shape\n",
    "    _, dy = y.shape\n",
    "    xy = np.hstack((X, y))\n",
    "\n",
    "    tree_xy = KDTree(xy)\n",
    "    eps = tree_xy.query(xy, k=k + 1, p=np.inf)[0][:, -1]\n",
    "    eps = np.nextafter(eps, 0)\n",
    "\n",
    "    nx = KDTree(X).query_ball_point(X, r=eps, p=np.inf, return_length=True) - 1\n",
    "    ny = KDTree(y).query_ball_point(y, r=eps, p=np.inf, return_length=True) - 1\n",
    "\n",
    "    digamma_N = digamma(n)\n",
    "    digamma_k = digamma(k)\n",
    "    digamma_nx = np.mean(digamma(nx + 1))\n",
    "    digamma_ny = np.mean(digamma(ny + 1))\n",
    "\n",
    "    Ixy = max(digamma_N + digamma_k - digamma_nx - digamma_ny, 0)\n",
    "    Hx = digamma_N - digamma_k + dx * np.mean(np.log(eps))\n",
    "    Hy = digamma_N - digamma_k + dy * np.mean(np.log(eps))\n",
    "    Hxy = digamma_N - digamma_k + (dx + dy) * np.mean(np.log(eps))\n",
    "\n",
    "    return Ixy, Hx, Hy, Hxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "559de504",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ixy, Hx, Hy, Hxy = mutual_information_ksg_full(encodings_reduced, y_scaled, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2f1114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5415387721710125,\n",
       " 7.771189200019949,\n",
       " 9.089621609519137,\n",
       " 7.701798020572623,\n",
       " 0.0595777025089674)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ixy, Hx, Hy, Hxy, Ixy / Hy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716fa5c",
   "metadata": {},
   "source": [
    "# cnn weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8469386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, feature_layer):\n",
    "        self.model = model\n",
    "        self.feature_layer = feature_layer\n",
    "        self.model.eval()\n",
    "        self.feature_grad = None\n",
    "        self.feature_map = None\n",
    "        self.hooks = []\n",
    "\n",
    "        # 最終層逆伝播時の勾配を記録する\n",
    "        # def save_feature_grad(module, in_grad, out_grad):\n",
    "        #     self.feature_grad = out_grad[0]\n",
    "        # self.hooks.append(self.feature_layer.register_backward_hook(save_feature_grad))\n",
    "\n",
    "        # 最終層の出力 Feature Map を記録する\n",
    "        def save_feature_map(module, inp, outp):\n",
    "            self.feature_map = outp[0].detach()\n",
    "        self.hooks.append(self.feature_layer.register_forward_hook(save_feature_map))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # def backward_on_target(self, output, target):\n",
    "    #     self.model.zero_grad()\n",
    "    #     one_hot_output = torch.zeros([1, output.size()[-1]],device=output.device)\n",
    "    #     one_hot_output[0][target] = 1\n",
    "    #     output.backward(gradient=one_hot_output, retain_graph=True)\n",
    "\n",
    "    def clear_hook(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4bf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet1d import ResNet1D\n",
    "config = {\n",
    "    \"network\":{\n",
    "        \"in_channels\":1,\n",
    "        \"base_filters\":64,\n",
    "        \"kernel_size\":3,\n",
    "        \"stride\":1,\n",
    "        \"groups\":1,\n",
    "        \"n_block\":5,\n",
    "        \"n_classes\":2,\n",
    "    },\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\":100,\n",
    "    \"log_interval\":100,\n",
    "    \"input_shape\":[1,1250],\n",
    "    \"output_path\": \"..\\\\outputs\\\\resnet\\\\0228\",\n",
    "    \"ppg\":10    \n",
    "          }\n",
    "model = ResNet1D(**config[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4dad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44ed530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111600, 1, 1250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsa\\AppData\\Local\\Temp\\ipykernel_22676\\1254599787.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('..\\\\outputs\\\\resnet\\\\0228\\\\best.pth'))\n",
      "100%|██████████| 872/872 [00:12<00:00, 68.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111616, 1250)\n"
     ]
    }
   ],
   "source": [
    "ppg = np.load(r\"F:\\minowa\\BloodPressureEstimation\\data\\processed\\BP_npy\\PulseDB\\test_4.npy\")\n",
    "print(ppg.shape)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('..\\\\outputs\\\\resnet\\\\0228\\\\best.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "loader = DataLoader(torch.from_numpy(ppg).float().to(device), batch_size=128, shuffle=False)\n",
    "gradcam = GradCAM(model, model.basicblock_list[-1].conv2)\n",
    "feature_maps = []\n",
    "for X in tqdm(loader):\n",
    "    # print(X.shape )\n",
    "    output = gradcam.forward(X)\n",
    "    # pred = torch.argmax(output, dim=1).item()\n",
    "    feature_map = gradcam.feature_map.cpu().data.numpy()\n",
    "    # print(feature_map.shape, feature_grad.shape) \n",
    "    # print(feature_map.shape)   \n",
    "    feature_maps.extend(feature_map.reshape(128,-1))\n",
    "feature_maps = np.stack(feature_maps)\n",
    "print(feature_maps.shape)\n",
    "pca = PCA(n_components=20)\n",
    "feature_maps_pca = pca.fit_transform(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5bd7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111600, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps_pca = feature_maps_pca[:111600]\n",
    "feature_maps_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b08a5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111616, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52bd12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111600,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.load(r\"F:\\minowa\\BloodPressureEstimation\\data\\processed\\BP_npy\\PulseDB\\test_sbp.npy\").reshape(-1,1).squeeze()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05174cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb6aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111600, 20) (111600, 1)\n",
      "MI value:0.1728568700892172\n",
      "Entropy of target (H_Y): 41.03853545032499\n",
      "Info-Fraction: 0.0042120623504815725\n"
     ]
    }
   ],
   "source": [
    "co = ite.cost.MIShannon_DKL(\n",
    "            mult=True, kl_co_name=\"BDKL_KnnK\", kl_co_pars={\"k\": 100}\n",
    "        )\n",
    "emb_dim = 20\n",
    "print(feature_maps_pca.shape, y_scaled.shape)\n",
    "val = co.estimation(np.hstack((feature_maps_pca, y_scaled)), [emb_dim, 1])\n",
    "H_Y = LDDP_entropy(y_scaled, bins=int(np.sqrt(len(y_scaled))))\n",
    "print(f\"MI value:{val}\")\n",
    "print(f\"Entropy of target (H_Y): {H_Y}\")\n",
    "info_fraction = val / H_Y\n",
    "print(f\"Info-Fraction: {info_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "906964c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.776519631958554"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.entropy(np.histogram(y_scaled,bins=int(np.sqrt(len(y_scaled))))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588d270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1fdac5ef3d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(\"F:\\\\minowa\\\\BloodPressureEstimation\\\\repos\\\\PPG-BP-Analysis\\\\autoencoder\\\\autoencoder_results_emb20_nb100.npz\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53023157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008290494713720849"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print keys\n",
    "max_mi = a['mi'].max()\n",
    "max_mi/ 41.03853545032499"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
