{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score\n",
    "# from resnet1d import ResNet1D\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# laveling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_data = np.load('../../data/processed/BP_npy/PulseDB/train_sbp_4.npy')\n",
    "\n",
    "# ラベリング関数の定義\n",
    "def label_blood_pressure(bp):\n",
    "    if bp <= 100:\n",
    "        return 0    # 正常血圧\n",
    "    elif 100 < bp < 120:\n",
    "        return 1    # 正常血圧\n",
    "    elif 120 <= bp < 140:\n",
    "        return 2    # 正常高値血圧\n",
    "    else:\n",
    "        return 3    # 高血圧\n",
    "\n",
    "# ベクトル化した関数を作成\n",
    "vectorized_label = np.vectorize(label_blood_pressure)\n",
    "\n",
    "# データ全体にラベリングを適用\n",
    "bp_labels = vectorized_label(bp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bp_class(df, sbp_col=\"sbp\", dbp_col=\"dbp\", new_col=\"bp_class\"):\n",
    "    \"\"\"\n",
    "    Add blood pressure class column based on SBP and DBP values.\n",
    "    \n",
    "    Categories:\n",
    "        0: sbp < 120 and dbp < 80\n",
    "        1: 120 <= sbp < 140 or 80 <= dbp < 90\n",
    "        2: sbp >= 140 or dbp >= 90\n",
    "    \"\"\"\n",
    "    \n",
    "    conditions = [\n",
    "        (df[sbp_col] < 120) & (df[dbp_col] < 80),\n",
    "        ((df[sbp_col] >= 120) & (df[sbp_col] < 140)) | ((df[dbp_col] >= 80) & (df[dbp_col] < 90)),\n",
    "        (df[sbp_col] >= 140) | (df[dbp_col] >= 90)\n",
    "    ]\n",
    "    \n",
    "    values = [0, 1, 2]\n",
    "    \n",
    "    df[new_col] = np.select(conditions, values, default=np.nan).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bp(arr,arr2):\n",
    "    \"\"\"\n",
    "    Add blood pressure class column based on SBP and DBP values.\n",
    "    \n",
    "    Categories:\n",
    "        0: sbp < 120 and dbp < 80\n",
    "        1: 120 <= sbp < 140 or 80 <= dbp < 90\n",
    "        2: sbp >= 140 or dbp >= 90\n",
    "    \"\"\"\n",
    "    \n",
    "    conditions = [\n",
    "        (arr < 120) & (arr2 < 80),\n",
    "        ((arr >= 120) & (arr < 140)) | ((arr2 >= 80) & (arr2 < 90)),\n",
    "        (arr >= 140) | (arr2 >= 90)\n",
    "    ]\n",
    "    \n",
    "    values = [0, 1, 2]\n",
    "    \n",
    "    class_arr = np.select(conditions, values)\n",
    "    return class_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bp_class\n",
       "0    26326\n",
       "1    17895\n",
       "2    10671\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import      pandas as pd\n",
    "q  =pd.read_parquet(r'F:\\minowa\\BloodPressureEstimation\\data\\processed\\PulseDB\\Downsampled\\test_features.parquet')\n",
    "q = add_bp_class(q, sbp_col=\"sbp\", dbp_col=\"dbp\", new_col=\"bp_class\")\n",
    "q['bp_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.7000e+01, 4.3900e+02, 1.8209e+04, 4.7756e+04, 3.3236e+04,\n",
       "        1.0214e+04, 1.6590e+03, 5.7000e+01, 1.1000e+01, 2.0000e+00]),\n",
       " array([ 28.7558563 ,  52.12690368,  75.49795106,  98.86899844,\n",
       "        122.24004582, 145.6110932 , 168.98214058, 192.35318796,\n",
       "        215.72423534, 239.09528272, 262.4663301 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGhCAYAAACDNqXeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkfElEQVR4nO3de2xUdfrH8acFWsqlrdxalFtdlItAWe5dF1eWLsgWVwUSUKOIgAGRcFGgdRGUmEAgq6BU2I1R+EPkkiy6UIFli2CUytVGQCHiFsGFUlApF2mh9PzyfJMzvxkoyAAy9On7lRxmzpxnzpw505n58D3f75koz/M8AQAAMCY60hsAAADwayDkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJPCCjkvv/yyREVFhUytW7cOLC8pKZExY8ZI/fr1pU6dOjJw4EA5evRoyDoOHjwoGRkZUqtWLWnUqJFMmjRJysrKQmo2btwonTp1ktjYWGnZsqUsWrTokm3Jzs6WFi1aSM2aNaV79+6ydevW8J89AAAwK+yWnHvuuUeOHDkSmD799NPAsgkTJsiqVatkxYoVsmnTJjl8+LAMGDAgsPzChQsu4Jw7d042b94sixcvdgFm2rRpgZqCggJX06tXL8nPz5fx48fLiBEjZN26dYGaZcuWycSJE2X69Omyc+dOSU1Nlb59+0pRUdH17Q0AAGBGVDg/0KktOR988IELHxcrLi6Whg0bypIlS2TQoEHutr1790qbNm0kLy9PevToIWvWrJH+/fu78JOUlORqFi5cKFOmTJFjx45JTEyMu56TkyO7d+8OrHvIkCFy4sQJWbt2rZvXlpuuXbvK/Pnz3Xx5ebk0bdpUxo4dK5mZmVf95PV+ui1169Z1rVIAAODWp9Hl1KlTcvvtt0t09BXaa7wwTJ8+3atVq5bXuHFjLyUlxXvssce87777zi3Lzc3VsOT99NNPIfdp1qyZ99prr7nrL730kpeamhqy/L///a+7386dO918z549vXHjxoXUvPPOO158fLy7Xlpa6lWrVs1buXJlSM2TTz7p/eUvf7ni9peUlHjFxcWB6auvvnKPzcTExMTExCSVbjp06NAVv/erh5OctAVFDy+1atXKHap65ZVXpGfPnq7VpbCw0LXEJCYmhtxHW2x0mdJLvwUneLm/7Eo1J0+elLNnz8pPP/3kDntVVKMtR1cyc+ZMt80XO3TokMTHx4ezKwAAQIRoJtAjOHok5krCCjn9+vULXO/QoYMLPc2bN5fly5dLXFyc3OqysrJcX56Ld5IGHEIOAACVyy91NbmuIeTaanP33XfL/v37JTk52XUo1r4zwXR0lS5TennxaCt//pdqNIRokGrQoIFUq1atwhp/HZejo7X8QEOwAQDAtusKOadPn5Zvv/1WGjduLJ07d5YaNWpIbm5uYPm+ffvckPG0tDQ3r5e7du0KGQW1fv16Fzbatm0bqAleh1/jr0MPieljBddoB2Kd92sAAADC6nj8/PPPexs3bvQKCgq8zz77zEtPT/caNGjgFRUVueWjRo1yHY03bNjgbd++3UtLS3OTr6yszGvXrp3Xp08fLz8/31u7dq3XsGFDLysrK6QjsnZunjRpkvf111972dnZrqOx1vqWLl3qxcbGeosWLXKdh5955hkvMTHRKywsDOfpuM7Hugv0EgAAVA5X+/0dVsgZPHiwG1kVExPj3XHHHW5+//79geVnz571nn32We+2225zQeWRRx7xjhw5ErKOAwcOeP369fPi4uJcQNLgdP78+ZCajz/+2OvYsaN7nDvvvNN79913L9mWN9980wUqrenWrZv3+eefe+Ei5AAAUPlc7fd3WOfJsUY7HickJLhz/NA/BwAAW9/f/HYVAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMKl6pDcAqGpaZOZIZXRgVkakNwEAwkJLDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAw6bpCzqxZsyQqKkrGjx8fuK2kpETGjBkj9evXlzp16sjAgQPl6NGjIfc7ePCgZGRkSK1ataRRo0YyadIkKSsrC6nZuHGjdOrUSWJjY6Vly5ayaNGiSx4/OztbWrRoITVr1pTu3bvL1q1br+fpAAAAQ6455Gzbtk3+/ve/S4cOHUJunzBhgqxatUpWrFghmzZtksOHD8uAAQMCyy9cuOACzrlz52Tz5s2yePFiF2CmTZsWqCkoKHA1vXr1kvz8fBeiRowYIevWrQvULFu2TCZOnCjTp0+XnTt3SmpqqvTt21eKioqu9SkBAABDojzP88K90+nTp10ry1tvvSWvvvqqdOzYUebOnSvFxcXSsGFDWbJkiQwaNMjV7t27V9q0aSN5eXnSo0cPWbNmjfTv39+Fn6SkJFezcOFCmTJlihw7dkxiYmLc9ZycHNm9e3fgMYcMGSInTpyQtWvXunltuenatavMnz/fzZeXl0vTpk1l7NixkpmZWeF2l5aWusl38uRJdx/d7vj4+HB3A3BNWmTmSGV0YFZGpDcBAALf3wkJCb/4/X1NLTl6OEpbWtLT00Nu37Fjh5w/fz7k9tatW0uzZs1cyFF62b59+0DAUdoCoxu8Z8+eQM3F69Yafx3aCqSPFVwTHR3t5v2aisycOdPtFH/SgAMAAGwKO+QsXbrUHR7SwHCxwsJC1xKTmJgYcrsGGl3m1wQHHH+5v+xKNRqEzp49K8ePH3eHvSqq8ddRkaysLJf6/OnQoUPhPn0AAFBJVA+nWEPBuHHjZP369a6zb2WjnZh1AgAA9oXVkqOHiLRjr/bHqV69upu0c/Ebb7zhrmtLih5K0r4zwXR0VXJysruulxePtvLnf6lGj7vFxcVJgwYNpFq1ahXW+OsAAABVW1ghp3fv3rJr1y434smfunTpIo8//njgeo0aNSQ3Nzdwn3379rkh42lpaW5eL3UdwaOgtGVIA0zbtm0DNcHr8Gv8deghsc6dO4fUaMdjnfdrAABA1RbW4aq6detKu3btQm6rXbu2OyeOf/vw4cPd0O569eq54KKjnTR46Mgq1adPHxdmnnjiCZk9e7brQzN16lTXmdk/lDRq1Cg3amry5Mny9NNPy4YNG2T58uVuxJVPH2Po0KEuWHXr1s2N7jpz5owMGzbsRuwXAABQlULO1Xj99dfdSCc9CaAO19ZRUTrU3KeHmVavXi2jR4924UdDkoaVGTNmBGpSUlJcoNFz7sybN0+aNGkib7/9tluXb/DgwW7IuZ5fR4OSDmPX4eUXd0YGAABV0zWdJ6eqjbMHbiTOkwMAt/B5cgAAAG51hBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYFL1SG8AgMqhRWaOVDYHZmVEehMARBAtOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AADCJkAMAAEwi5AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMCivkLFiwQDp06CDx8fFuSktLkzVr1gSWl5SUyJgxY6R+/fpSp04dGThwoBw9ejRkHQcPHpSMjAypVauWNGrUSCZNmiRlZWUhNRs3bpROnTpJbGystGzZUhYtWnTJtmRnZ0uLFi2kZs2a0r17d9m6dWv4zx4AAJgVVshp0qSJzJo1S3bs2CHbt2+XP/7xj/LQQw/Jnj173PIJEybIqlWrZMWKFbJp0yY5fPiwDBgwIHD/CxcuuIBz7tw52bx5syxevNgFmGnTpgVqCgoKXE2vXr0kPz9fxo8fLyNGjJB169YFapYtWyYTJ06U6dOny86dOyU1NVX69u0rRUVFN2avAACASi/K8zzvelZQr149mTNnjgwaNEgaNmwoS5YscdfV3r17pU2bNpKXlyc9evRwrT79+/d34ScpKcnVLFy4UKZMmSLHjh2TmJgYdz0nJ0d2794deIwhQ4bIiRMnZO3atW5eW266du0q8+fPd/Pl5eXStGlTGTt2rGRmZl71tp88eVISEhKkuLjYtUwBN0OLzJxIb0KVcWBWRqQ3AcCv4Gq/v6+5T462yixdulTOnDnjDltp68758+clPT09UNO6dWtp1qyZCzlKL9u3bx8IOEpbYHRj/dYgrQleh1/jr0NbgfSxgmuio6PdvF9zOaWlpe6xgicAAGBT2CFn165drr+N9pcZNWqUrFy5Utq2bSuFhYWuJSYxMTGkXgONLlN6GRxw/OX+sivVaCA5e/asHD9+3AWsimr8dVzOzJkzXfLzJ239AQAANoUdclq1auX6ymzZskVGjx4tQ4cOla+++koqg6ysLNe05U+HDh2K9CYBAIBfSfVw76CtNTriSXXu3Fm2bdsm8+bNk8GDB7tDSdp3Jrg1R0dXJScnu+t6efEoKH/0VXDNxSOydF6PucXFxUm1atXcVFGNv47L0dYnnQAAgH3XfZ4c7fSrfV008NSoUUNyc3MDy/bt2+eGjGufHaWXergreBTU+vXrXYDRQ15+TfA6/Bp/HRqy9LGCa3QbdN6vAQAAqB7u4Z5+/fq5zsSnTp1yI6n0nDY6vFv7uAwfPtwN7dYRVxpcdLSTBg8dWaX69OnjwswTTzwhs2fPdn1opk6d6s6t47ewaD8fHTU1efJkefrpp2XDhg2yfPlyN+LKp4+hh8m6dOki3bp1k7lz57oO0MOGDbvR+wcAAFSFkKMtME8++aQcOXLEhRo9MaAGnD/96U9u+euvv+5GOulJALV1R0dFvfXWW4H762Gm1atXu748Gn5q167twsqMGTMCNSkpKS7Q6Dl39DCYnpvn7bffduvy6aExHXKu59fRoNSxY0c3vPzizsgAAKDquu7z5FRmnCcHkcB5cm4ezpMD2PSrnycHAADgVkbIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASWGFnJkzZ0rXrl2lbt260qhRI3n44Ydl3759ITUlJSUyZswYqV+/vtSpU0cGDhwoR48eDak5ePCgZGRkSK1atdx6Jk2aJGVlZSE1GzdulE6dOklsbKy0bNlSFi1adMn2ZGdnS4sWLaRmzZrSvXt32bp1a3jPHgAAmBVWyNm0aZMLMJ9//rmsX79ezp8/L3369JEzZ84EaiZMmCCrVq2SFStWuPrDhw/LgAEDAssvXLjgAs65c+dk8+bNsnjxYhdgpk2bFqgpKChwNb169ZL8/HwZP368jBgxQtatWxeoWbZsmUycOFGmT58uO3fulNTUVOnbt68UFRVd/14BAACVXpTned613vnYsWOuJUbDzH333SfFxcXSsGFDWbJkiQwaNMjV7N27V9q0aSN5eXnSo0cPWbNmjfTv39+Fn6SkJFezcOFCmTJliltfTEyMu56TkyO7d+8OPNaQIUPkxIkTsnbtWjevLTfaqjR//nw3X15eLk2bNpWxY8dKZmbmVW3/yZMnJSEhwW13fHz8te4GICwtMnMivQlVxoFZGZHeBAC/gqv9/r6uPjm6clWvXj13uWPHDte6k56eHqhp3bq1NGvWzIUcpZft27cPBBylLTC6wXv27AnUBK/Dr/HXoa1A+ljBNdHR0W7er6lIaWmpe5zgCQAA2HTNIUdbTvQw0r333ivt2rVztxUWFrqWmMTExJBaDTS6zK8JDjj+cn/ZlWo0lJw9e1aOHz/uDntVVOOv43J9ijT5+ZO2/AAAAJuuOeRo3xw9nLR06VKpLLKyslzrkz8dOnQo0psEAAB+JdWv5U7PPfecrF69Wj755BNp0qRJ4Pbk5GR3KEn7zgS35ujoKl3m11w8CsoffRVcc/GILJ3X425xcXFSrVo1N1VU46+jIjpSSycAAGBfWC052kdZA87KlStlw4YNkpKSErK8c+fOUqNGDcnNzQ3cpkPMdch4Wlqam9fLXbt2hYyC0pFaGmDatm0bqAleh1/jr0MPieljBdfo4TOd92sAAEDVVj3cQ1Q6curDDz9058rx+79o/xZtYdHL4cOHu6Hd2hlZg4uOdtLgoSOrlA451zDzxBNPyOzZs906pk6d6tbtt7KMGjXKjZqaPHmyPP300y5QLV++3I248uljDB06VLp06SLdunWTuXPnuqHsw4YNu7F7CAAA2A85CxYscJf3339/yO3vvvuuPPXUU+7666+/7kY66UkAdTSTjop66623ArV6mEkPdY0ePdqFn9q1a7uwMmPGjECNthBpoNFz7sybN88dEnv77bfdunyDBw92Q871/DoalDp27OiGl1/cGRkAAFRN13WenMqO8+QgEjhPzs3DeXIAm27KeXIAAABuVYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGDSNf2sA3CrYDg2AOByaMkBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmBR2yPnkk0/kwQcflNtvv12ioqLkgw8+CFnueZ5MmzZNGjduLHFxcZKeni7ffPNNSM2PP/4ojz/+uMTHx0tiYqIMHz5cTp8+HVLz5ZdfSs+ePaVmzZrStGlTmT179iXbsmLFCmndurWrad++vXz00UfhPh0AAGBU2CHnzJkzkpqaKtnZ2RUu1zDyxhtvyMKFC2XLli1Su3Zt6du3r5SUlARqNODs2bNH1q9fL6tXr3bB6ZlnngksP3nypPTp00eaN28uO3bskDlz5sjLL78s//jHPwI1mzdvlkcffdQFpC+++EIefvhhN+3evTv8vQAAAMyJ8rTp5VrvHBUlK1eudOFC6aq0hef555+XF154wd1WXFwsSUlJsmjRIhkyZIh8/fXX0rZtW9m2bZt06dLF1axdu1b+/Oc/y/fff+/uv2DBAvnrX/8qhYWFEhMT42oyMzNdq9HevXvd/ODBg13g0pDk69Gjh3Ts2NEFrKuhYSohIcFto7YqofJpkZkT6U0AbqgDszIivQnALe9qv79vaJ+cgoICF0z0EJVPN6J79+6Sl5fn5vVSD1H5AUdpfXR0tGv58Wvuu+++QMBR2hq0b98++emnnwI1wY/j1/iPU5HS0lK3Y4InAABg0w0NORpwlLbcBNN5f5leNmrUKGR59erVpV69eiE1Fa0j+DEuV+Mvr8jMmTNd6PIn7esDAABsqlKjq7KyslzTlj8dOnQo0psEAAAqQ8hJTk52l0ePHg25Xef9ZXpZVFQUsrysrMyNuAquqWgdwY9xuRp/eUViY2PdsbvgCQAA2HRDQ05KSooLGbm5uYHbtN+L9rVJS0tz83p54sQJN2rKt2HDBikvL3d9d/waHXF1/vz5QI2OxGrVqpXcdtttgZrgx/Fr/McBAABVW9ghR89nk5+f7ya/s7FeP3jwoBttNX78eHn11VflX//6l+zatUuefPJJN2LKH4HVpk0beeCBB2TkyJGydetW+eyzz+S5555zI6+0Tj322GOu07EOD9eh5suWLZN58+bJxIkTA9sxbtw4Nyrrb3/7mxtxpUPMt2/f7tYFAABQPdw7aJDo1atXYN4PHkOHDnXDxCdPnuyGdut5b7TF5ve//70LI3rCPt97773nwkjv3r3dqKqBAwe6c+v4tFPwv//9bxkzZox07txZGjRo4E4wGHwund/97neyZMkSmTp1qrz44oty1113uSHm7dq1u579AQAAjLiu8+RUdpwnp/LjPDmwhvPkALfoeXIAAABuFYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJhFyAACASYQcAABgEiEHAACYRMgBAAAmEXIAAIBJhBwAAGBS9UhvAADg/7XIzJHK5sCsjEhvAlAhWnIAAIBJhBwAAGASIQcAAJhEyAEAACYRcgAAgEmEHAAAYBIhBwAAmETIAQAAJlX6kwFmZ2fLnDlzpLCwUFJTU+XNN9+Ubt26RXqzKqXKeBIyAABMtuQsW7ZMJk6cKNOnT5edO3e6kNO3b18pKiqK9KYBAIAIq9QtOa+99pqMHDlShg0b5uYXLlwoOTk58s4770hmZuYl9aWlpW7yFRcXu8uTJ0/exK2+dZWX/hzpTQBQCfEZikj9zXmeZzPknDt3Tnbs2CFZWVmB26KjoyU9PV3y8vIqvM/MmTPllVdeueT2pk2b/qrbCgCWJcyN9Bagqjp16pQkJCTYCznHjx+XCxcuSFJSUsjtOr93794K76OBSA9v+crLy+XHH3+U+vXrS1RUlFS1FKzh7tChQxIfHx/pzamSeA0ii/0febwGkXWyEu9/bcHRgHP77bdfsa7ShpxrERsb66ZgiYmJUpXpH3Zl++O2htcgstj/kcdrEFnxlXT/X6kFp9J3PG7QoIFUq1ZNjh49GnK7zicnJ0dsuwAAwK2h0oacmJgY6dy5s+Tm5oYcftL5tLS0iG4bAACIvEp9uEr71wwdOlS6dOnizo0zd+5cOXPmTGC0FS5PD9vp0PuLD9/h5uE1iCz2f+TxGkRWbBXY/1HeL42/usXNnz8/cDLAjh07yhtvvCHdu3eP9GYBAIAIq/QhBwAAwFSfHAAAgCsh5AAAAJMIOQAAwCRCDgAAMImQY9jLL7/sfq4ieGrdunVgeUlJiYwZM8b9rEWdOnVk4MCBl5xcEeH55JNP5MEHH3SnGtf9/cEHH4Qs137+06ZNk8aNG0tcXJz7rbVvvvkmpEZ/auTxxx93ZyDVM3IPHz5cTp8+fZOfic39/9RTT13ynnjggQdCatj/105/H7Br165St25dadSokTz88MOyb9++kJqr+dw5ePCgZGRkSK1atdx6Jk2aJGVlZTf52dh9De6///5L3gejRo0y+RoQcoy755575MiRI4Hp008/DSybMGGCrFq1SlasWCGbNm2Sw4cPy4ABAyK6vZWdnqcpNTVVsrOzK1w+e/Zsd5qDhQsXypYtW6R27drSt29f98Hv0y/YPXv2yPr162X16tXui/uZZ565ic/C7v5XGmqC3xPvv/9+yHL2/7XTzxENMJ9//rnbf+fPn5c+ffq41+VqP3f0Nwn1y1V/hHnz5s2yePFiWbRokfvPAW7Ma6BGjhwZ8j7QzyaTr4EOIYdN06dP91JTUytcduLECa9GjRreihUrArd9/fXXejoBLy8v7yZupV26L1euXBmYLy8v95KTk705c+aEvA6xsbHe+++/7+a/+uord79t27YFatasWeNFRUV5//vf/27yM7C1/9XQoUO9hx566LL3Yf/fWEVFRW5/btq06ao/dz766CMvOjraKywsDNQsWLDAi4+P90pLSyPwLGy9BuoPf/iDN27cOO9yLL0GtOQYp4dCtOn+zjvvdP9D1SZItWPHDpfw9XCJTw9lNWvWTPLy8iK4xXYVFBS4k1YG73P9gTk9eaW/z/VSD5HoWbx9Wh8dHe1afnD9Nm7c6JrfW7VqJaNHj5YffvghsIz9f2MVFxe7y3r16l31545etm/fXpKSkgI12tqpv5itLWy4vtfA995777nfgGzXrp1kZWXJzz//HFhm6TWo1D/rgCvTL09tYtQPc22OfOWVV6Rnz56ye/du92Wrv/918a+w6x+1LsON5+/X4A8Of95fppf6BRysevXq7gOK1+X66aEqPTSSkpIi3377rbz44ovSr18/96GuP/jL/r9x9LcEx48fL/fee6/7IlVX87mjlxW9R/xluL7XQD322GPSvHlz9x/gL7/8UqZMmeL67fzzn/809xoQcgzTD29fhw4dXOjRP+zly5e7Tq9AVTNkyJDAdf2fqr4vfvOb37jWnd69e0d026zRfiH6H6rgfoC4NV6DZ4L6mOn7QAdC6N+/Bn99P1jC4aoqRP/3dPfdd8v+/fslOTnZdSo7ceJESI2OctBluPH8/XrxSJLgfa6XRUVFIct1RIOO+OF1ufH0MK422et7QrH/b4znnnvOddr++OOPpUmTJoHbr+ZzRy8reo/4y3B9r0FF/N97DH4fWHkNCDlViA6D1aSuqb1z585So0YNyc3NDSzX5krts5OWlhbR7bRKD5HoB0TwPtdj3NrXw9/neqlfANp3wbdhwwbX7MwPz95433//veuTo+8Jxf6/PtrfW79cV65c6fab/s0Hu5rPHb3ctWtXSNjUUUI6pL9t27Y38dlUTr/0GlQkPz/fXQa/D8y8BpHu+Yxfz/PPP+9t3LjRKygo8D777DMvPT3da9Cggettr0aNGuU1a9bM27Bhg7d9+3YvLS3NTbh2p06d8r744gs36dvrtddec9e/++47t3zWrFleYmKi9+GHH3pffvmlG+mTkpLinT17NrCOBx54wPvtb3/rbdmyxfv000+9u+66y3v00Ucj+Kxs7H9d9sILL7hRPPqe+M9//uN16tTJ7d+SkpLAOtj/12706NFeQkKC+9w5cuRIYPr5558DNb/0uVNWVua1a9fO69Onj5efn++tXbvWa9iwoZeVlRWhZ2XrNdi/f783Y8YMt+/1faCfRXfeead33333mXwNCDmGDR482GvcuLEXExPj3XHHHW5e/8B9+sX67LPPerfddptXq1Yt75FHHnFvBly7jz/+2H25Xjzp0GV/GPlLL73kJSUluaHjvXv39vbt2xeyjh9++MF9qdapU8cN2Rw2bJj7gsb17X/9kNcPbf2w1mHMzZs390aOHBkyTFax/69dRftep3fffTesz50DBw54/fr18+Li4tx/zPQ/bOfPn4/AM7L3Ghw8eNAFmnr16rnPoJYtW3qTJk3yiouLTb4GUfpPpFuTAAAAbjT65AAAAJMIOQAAwCRCDgAAMImQAwAATCLkAAAAkwg5AADAJEIOAAAwiZADAABMIuQAAACTCDkAAMAkQg4AABCL/g9rGWjnj7w/ngAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.load('../../data/processed/BP_npy/PulseDB/test_sbp.npy')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39361, 1, 1250]) torch.Size([39361])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([ 1294, 38067]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = BPDataset(train=False, data_dir='../../data/processed/BP_npy/PulseDB',cv=False)\n",
    "test_dataset.y.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベルの分布:\n",
      "ラベル 0: 171782件\n",
      "ラベル 3: 140660件\n"
     ]
    }
   ],
   "source": [
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(bp_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/processed/BP_npy/PulseDB/test_sbp_4labels.npy', bp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2値\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = add_bp(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 111600\n",
      "フィルタ後のデータ数: 38110\n",
      "ラベルの分布:\n",
      "ラベル 0: 20674件\n",
      "ラベル 1: 17436件\n"
     ]
    }
   ],
   "source": [
    "# ラベルデータの読み込み\n",
    "labels = np.load('../../data/processed/BP_npy/PulseDB/test_sbp_4labels.npy')\n",
    "\n",
    "# ラベルが0または3のインデックスを抽出\n",
    "mask = (labels == 0) | (labels == 3)\n",
    "selected_indices = np.where(mask)[0]\n",
    "\n",
    "# 対応するデータの抽出\n",
    "original_data = np.load('../../data/processed/BP_npy/PulseDB/test.npy')\n",
    "filtered_data = original_data[selected_indices]\n",
    "filtered_labels = labels[selected_indices]\n",
    "filtered_labels[filtered_labels==3]=1\n",
    "# 確認\n",
    "print(f\"元のデータ数: {len(labels)}\")\n",
    "print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(filtered_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")\n",
    "\n",
    "# 必要に応じて新しいファイルとして保存\n",
    "np.save('../../data/processed/BP_npy/PulseDB/test_2.npy', filtered_data)\n",
    "np.save('../../data/processed/BP_npy/PulseDB/test_sbp_2labels.npy', filtered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv\n",
    "cv[0][:5] : train  \n",
    "cv[1][:5] : val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902160,)\n"
     ]
    }
   ],
   "source": [
    "cv_idx_path = r\"../../data/processed/BP_npy/PulseDB/cv_5fold.pkl\"\n",
    "with open(cv_idx_path, \"rb\") as f:\n",
    "    cv_idx = pickle.load(f)\n",
    "labels = np.load('../../data/processed/BP_npy/PulseDB/train_sbp_4labels.npy')\n",
    "train_sbp = []\n",
    "val_sbp = []\n",
    "train_idx = []\n",
    "val_idx = []\n",
    "for fold in range(5):\n",
    "    train_ = labels[cv_idx[0][fold]]\n",
    "    idx_ = np.where((train_==0)|(train_==3))\n",
    "    train_idx.append(idx_)\n",
    "    train_ = train_[idx_]\n",
    "    # train_[train_==0]=0\n",
    "    train_[train_==3]=1\n",
    "    train_sbp.append(train_)\n",
    "    val_ = labels[cv_idx[1][fold]]\n",
    "    idx_ = np.where((val_==0)|(val_==3))\n",
    "    val_idx.append(idx_)\n",
    "    val_ = val_[idx_]\n",
    "    # val_[val_==0]=0\n",
    "    val_[val_==3]=1\n",
    "    val_sbp.append(val_)\n",
    "sbp_2labels_cv = [train_sbp,val_sbp]\n",
    "ppgidx_2labels_cv = [train_idx,val_idx]\n",
    "with open('../../data/processed/BP_npy/PulseDB/ppgidx_2labels_cv.pkl','wb') as f:\n",
    "    pickle.dump(ppgidx_2labels_cv,f)\n",
    "with open('../../data/processed/BP_npy/PulseDB/sbp_2labels_cv.pkl','wb') as f:\n",
    "    pickle.dump(sbp_2labels_cv,f)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 902160\n",
      "フィルタ後のデータ数: 312442\n",
      "ラベルの分布:\n",
      "ラベル 0: 171782件\n",
      "ラベル 1: 140660件\n"
     ]
    }
   ],
   "source": [
    "# ラベルデータの読み込み\n",
    "labels = np.load('../../data/processed/BP_npy/PulseDB/train_sbp_4labels.npy')\n",
    "\n",
    "# ラベルが0または3のインデックスを抽出\n",
    "mask = (labels == 0) | (labels == 3)\n",
    "selected_indices = np.where(mask)[0]\n",
    "\n",
    "# 対応するデータの抽出\n",
    "original_data = np.load('../../data/processed/BP_npy/PulseDB/train.npy')\n",
    "filtered_data = original_data[selected_indices]\n",
    "filtered_labels = labels[selected_indices]\n",
    "filtered_labels[filtered_labels==3]=1\n",
    "# 確認\n",
    "print(f\"元のデータ数: {len(labels)}\")\n",
    "print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(filtered_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")\n",
    "\n",
    "# 必要に応じて新しいファイルとして保存\n",
    "np.save('../../data/processed/BP_npy/PulseDB/train_2.npy', filtered_data)\n",
    "np.save('../../data/processed/BP_npy/PulseDB/train_sbp_2labels.npy', filtered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# laveling retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902160,)\n"
     ]
    }
   ],
   "source": [
    "bp_data = np.load('../../data/processed/BP_npy/PulseDB/train_sbp.npy')\n",
    "print(bp_data.shape)\n",
    "# ラベリング関数の定義\n",
    "def label_blood_pressure(bp):\n",
    "    if bp <= 100:\n",
    "        return 0    # 正常血圧\n",
    "    elif 100 < bp < 120:\n",
    "        return 1    # 正常血圧\n",
    "    elif 120 < bp < 140:\n",
    "        return 2    # 正常高値血圧\n",
    "    else:\n",
    "        return 3    # 高血圧\n",
    "\n",
    "# ベクトル化した関数を作成\n",
    "vectorized_label = np.vectorize(label_blood_pressure)\n",
    "\n",
    "# データ全体にラベリングを適用\n",
    "bp_labels = vectorized_label(bp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 902160\n",
      "ラベルの分布:\n",
      "ラベル 0: 171782件\n",
      "ラベル 1: 336150件\n",
      "ラベル 2: 253568件\n",
      "ラベル 3: 140660件\n"
     ]
    }
   ],
   "source": [
    "# 確認\n",
    "print(f\"元のデータ数: {len(bp_labels)}\")\n",
    "# print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(bp_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/processed/BP_npy/PulseDB/train_sbp_labels.npy',bp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 902160\n",
      "フィルタ後のデータ数: 312442\n",
      "ラベルの分布:\n",
      "ラベル 0: 171782件\n",
      "ラベル 1: 140660件\n"
     ]
    }
   ],
   "source": [
    "labels = np.load('../../data/processed/BP_npy/PulseDB/train_sbp_labels.npy')\n",
    "\n",
    "# ラベルが0または3のインデックスを抽出\n",
    "mask = (labels == 0) | (labels == 3)\n",
    "selected_indices = np.where(mask)[0]\n",
    "\n",
    "# 対応するデータの抽出\n",
    "original_data = np.load('../../data/processed/BP_npy/PulseDB/train_raw.npy')\n",
    "filtered_data = original_data[selected_indices]\n",
    "filtered_labels = labels[selected_indices]\n",
    "filtered_labels[filtered_labels==3]=1\n",
    "# 確認\n",
    "print(f\"元のデータ数: {len(labels)}\")\n",
    "print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(filtered_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")\n",
    "\n",
    "# 必要に応じて新しいファイルとして保存\n",
    "np.save('../../data/processed/BP_npy/PulseDB/train_2.npy', filtered_data)\n",
    "np.save('../../data/processed/BP_npy/PulseDB/train_sbp_2labels.npy', filtered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 111600\n",
      "ラベルの分布:\n",
      "ラベル 0: 20674件\n",
      "ラベル 1: 41043件\n",
      "ラベル 2: 32447件\n",
      "ラベル 3: 17436件\n"
     ]
    }
   ],
   "source": [
    "bp_data = np.load('../../data/processed/BP_npy/PulseDB/test_sbp.npy')\n",
    "vectorized_label = np.vectorize(label_blood_pressure)\n",
    "# データ全体にラベリングを適用\n",
    "bp_labels = vectorized_label(bp_data)\n",
    "# 確認\n",
    "print(f\"元のデータ数: {len(bp_labels)}\")\n",
    "# print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(bp_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/processed/BP_npy/PulseDB/test_sbp_labels.npy',bp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のデータ数: 111600\n",
      "フィルタ後のデータ数: 38110\n",
      "ラベルの分布:\n",
      "ラベル 0: 20674件\n",
      "ラベル 1: 17436件\n"
     ]
    }
   ],
   "source": [
    "labels = np.load('../../data/processed/BP_npy/PulseDB/test_sbp_labels.npy')\n",
    "\n",
    "# ラベルが0または3のインデックスを抽出\n",
    "mask = (labels == 0) | (labels == 3)\n",
    "selected_indices = np.where(mask)[0]\n",
    "\n",
    "# 対応するデータの抽出\n",
    "original_data = np.load('../../data/processed/BP_npy/PulseDB/test_raw.npy')\n",
    "filtered_data = original_data[selected_indices]\n",
    "filtered_labels = labels[selected_indices]\n",
    "filtered_labels[filtered_labels==3]=1\n",
    "# 確認\n",
    "print(f\"元のデータ数: {len(labels)}\")\n",
    "print(f\"フィルタ後のデータ数: {len(filtered_labels)}\")\n",
    "print(\"ラベルの分布:\")\n",
    "unique, counts = np.unique(filtered_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"ラベル {label}: {count}件\")\n",
    "\n",
    "# 必要に応じて新しいファイルとして保存\n",
    "np.save('../../data/processed/BP_npy/PulseDB/test_2.npy', filtered_data)\n",
    "np.save('../../data/processed/BP_npy/PulseDB/test_sbp_2labels.npy', filtered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv laveling retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902160,)\n"
     ]
    }
   ],
   "source": [
    "cv_idx_path = r\"../../data/processed/BP_npy/PulseDB/cv_5fold_2labels.pkl\"\n",
    "with open(cv_idx_path, \"rb\") as f:\n",
    "    cv_idx = pickle.load(f)\n",
    "labels = np.load('../../data/processed/BP_npy/PulseDB/train_sbp_2labels.npy')\n",
    "train_sbp = []\n",
    "val_sbp = []\n",
    "train_idx = []\n",
    "val_idx = []\n",
    "for fold in range(5):\n",
    "    train_ = labels[cv_idx[0][fold]]\n",
    "    idx_ = np.where((train_==0)|(train_==3))\n",
    "    train_idx.append(idx_)\n",
    "    train_ = train_[idx_]\n",
    "    # train_[train_==0]=0\n",
    "    train_[train_==3]=1\n",
    "    train_sbp.append(train_)\n",
    "    val_ = labels[cv_idx[1][fold]]\n",
    "    idx_ = np.where((val_==0)|(val_==3))\n",
    "    val_idx.append(idx_)\n",
    "    val_ = val_[idx_]\n",
    "    # val_[val_==0]=0\n",
    "    val_[val_==3]=1\n",
    "    val_sbp.append(val_)\n",
    "sbp_2labels_cv = [train_sbp,val_sbp]\n",
    "ppgidx_2labels_cv = [train_idx,val_idx]\n",
    "with open('../../data/processed/BP_npy/PulseDB/ppgidx_2labels_cv.pkl','wb') as f:\n",
    "    pickle.dump(ppgidx_2labels_cv,f)\n",
    "with open('../../data/processed/BP_npy/PulseDB/sbp_2labels_cv.pkl','wb') as f:\n",
    "    pickle.dump(sbp_2labels_cv,f)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BPDataset(Dataset):\n",
    "#     def __init__(self, data_dir,train=True):\n",
    "#         # Load data\n",
    "#         if train:\n",
    "#             self.x = np.load(f'{data_dir}/train.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "#             self.y = np.load(f'{data_dir}/train_sbp_4labels.npy')  # Shape: (-1,)\n",
    "#             print(self.x.shape,self.y.shape)\n",
    "#             # self.x = np.load(f'{data_dir}/train_2.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "#             # self.y = np.load(f'{data_dir}/train_sbp_2labels.npy')  # Shape: (-1,)\n",
    "#         else:\n",
    "#             self.x = np.load(f'{data_dir}/test.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "#             self.y = np.load(f'{data_dir}/test_sbp_4labels.npy')  # Shape: (-1,)\n",
    "#             # self.x = np.load(f'{data_dir}/test_2.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "#             # self.y = np.load(f'{data_dir}/test_sbp_2labels.npy')  # Shape: (-1,)\n",
    "        \n",
    "#         # Convert to torch tensors\n",
    "#         self.x = torch.FloatTensor(self.x)\n",
    "#         self.y = torch.LongTensor(self.y)\n",
    "#         print(self.x.shape,self.y.shape)\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.x[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPDataset(Dataset):\n",
    "    def __init__(self, data_dir,cv=False,fold=None,train=True):\n",
    "        # Load data\n",
    "        if train:\n",
    "            if cv:\n",
    "                self.x = np.load(f'{data_dir}/train_2.npy')[:, 1, :].reshape(-1,1,1250)\n",
    "                self.y = np.load(f'{data_dir}/train_sbp_2labels.npy')\n",
    "                with open(f'{data_dir}/cv_5fold_2labels.pkl','rb') as f:\n",
    "                    file = pickle.load(f)\n",
    "                    self.x = self.x[file[0][fold]]\n",
    "                    self.y = self.y[file[0][fold]]\n",
    "                # with open(f'{data_dir}/ppgidx_2labels_cv.pkl','rb') as f:\n",
    "                #     ppgidx_2labels_cv = pickle.load(f)\n",
    "                # self.x = self.x[ppgidx_2labels_cv[0][fold]]\n",
    "                # with open(f'{data_dir}/sbp_2labels_cv.pkl','rb') as f:\n",
    "                #     sbp_4labels_cv = pickle.load(f)\n",
    "            else:\n",
    "                self.x = np.load(f'{data_dir}/train_4.npy')[:, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "                self.y = np.load(f'{data_dir}/train_sbp.npy') \n",
    "                dbp = np.load(f'{data_dir}/train_dbp.npy')\n",
    "                self.y = add_bp(self.y, dbp)# Shape: (-1,)\n",
    "                self.x = self.x[self.y!=2]\n",
    "                self.y = self.y[self.y!=2]\n",
    "            print(self.x.shape,self.y.shape)\n",
    "            # self.x = np.load(f'{data_dir}/train_2.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "            # self.y = np.load(f'{data_dir}/train_sbp_2labels.npy')  # Shape: (-1,)\n",
    "        else:\n",
    "            if cv:\n",
    "                self.x = np.load(f'{data_dir}/train_4.npy')[:, 1, :].reshape(-1,1,1250) # Shape: (-1, 1250)\n",
    "                self.y = np.load(f'{data_dir}/train_sbp.npy')\n",
    "                with open(f'{data_dir}/cv_5fold_2labels.pkl','rb') as f:\n",
    "                    file = pickle.load(f)\n",
    "                    self.x = self.x[file[1][fold]]\n",
    "                    self.y = self.y[file[1][fold]]\n",
    "                # with open(f'{data_dir}/ppgidx_2labels_cv.pkl','rb') as f:\n",
    "                #     ppgidx_2labels_cv = pickle.load(f)\n",
    "                # self.x = self.x[ppgidx_2labels_cv[1][fold]]\n",
    "                # with open(f'{data_dir}/sbp_2labels_cv.pkl','rb') as f:\n",
    "                #     sbp_4labels_cv = pickle.load(f)\n",
    "                # self.y = sbp_4labels_cv[1][fold]  # Shape: (-1,)\n",
    "            else:\n",
    "                self.x = np.load(f'{data_dir}/test_4.npy')[:, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "                self.y = np.load(f'{data_dir}/test_sbp.npy')  # Shape: (-1,)\n",
    "                dbp = np.load(f'{data_dir}/test_dbp.npy')\n",
    "                self.y = add_bp(self.y, dbp)\n",
    "                self.x = self.x[self.y!=2]\n",
    "                self.y = self.y[self.y!=2]\n",
    "            # self.x = np.load(f'{data_dir}/test_2.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "            # self.y = np.load(f'{data_dir}/test_sbp_2labels.npy')  # Shape: (-1,)\n",
    "        # Convert to torch tensors\n",
    "        self.x = torch.FloatTensor(self.x)\n",
    "        self.y = torch.LongTensor(self.y)\n",
    "        print(self.x.shape,self.y.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPDataset_Regr(Dataset):\n",
    "    def __init__(self, data_dir,cv=None,train=True):\n",
    "        # Load data\n",
    "        if train:\n",
    "            self.x = np.load(f'{data_dir}/train.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "            self.sbp = np.load(f'{data_dir}/train_sbp.npy')  # Shape: (-1,)\n",
    "            self.dbp = np.load(f'{data_dir}/train_dbp.npy')  # Shape: (-1,)\n",
    "        else:\n",
    "            if cv is not None:\n",
    "                self.x = np.load(f'{data_dir}/train.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "                self.sbp = np.load(f'{data_dir}/train_sbp.npy')  # Shape: (-1,)\n",
    "                self.dbp = np.load(f'{data_dir}/train_dbp.npy')\n",
    "\n",
    "            else:\n",
    "                self.x = np.load(f'{data_dir}/test.npy')[:, 1, :].reshape(-1,1,1250)  # Shape: (-1, 1250)\n",
    "                self.sbp = np.load(f'{data_dir}/test_sbp.npy')  # Shape: (-1,)\n",
    "                self.dbp = np.load(f'{data_dir}/test_dbp.npy')  # Shape: (-1,)\n",
    "        if cv is not None:\n",
    "            self.x = self.x[cv]\n",
    "            self.sbp = self.sbp[cv]\n",
    "            self.dbp = self.dbp[cv]\n",
    "        scale = np.load(f'{data_dir}/scale_train.npy')\n",
    "        self.sbp = self.sbp * scale[0,1]- scale[0,0]\n",
    "        self.dbp = self.dbp * scale[0,1] - scale[0,0]\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        self.x = torch.FloatTensor(self.x)\n",
    "        self.sbp = torch.FloatTensor(self.sbp)\n",
    "        self.dbp = torch.FloatTensor(self.dbp)\n",
    "        print(self.x.shape,self.sbp.shape,self.dbp.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.sbp[idx],self.dbp[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"earlystoppingクラス\"\"\"\n",
    "\n",
    "    def __init__(self, path, patience=5, verbose=False):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        # self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "        \n",
    "        self.path = path             #ベストモデル格納path\n",
    "        os.makedirs(os.path.dirname(self.path),exist_ok=True)\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score\n",
    "            self.checkpoint(score, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score > self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する\n",
    "                print(f\"the best of loss: {self.best_score:.5f}\")\n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.checkpoint(score, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, score, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.best_score:.5f} --> {score:.5f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  #ベストモデルを指定したpathに保存\n",
    "        self.best_score = score #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_warning(config):\n",
    "    # 'output_path'が存在する場合\n",
    "    if os.path.exists(config[\"output_path\"]):\n",
    "        # ユーザーに確認を求める（enterを押したらyes）\n",
    "        confirmation = input(f\"Warning: The output path {config['output_path']} already exists. Do you want to continue? Press Enter to continue: \").strip().lower()\n",
    "        \n",
    "        # 入力が空（Enter）が押された場合は続行、それ以外はエラー\n",
    "        if confirmation == \"\" or confirmation == \"y\":\n",
    "            print(\"Proceeding with the operation...\")\n",
    "        else:\n",
    "            raise ValueError(\"Operation aborted by the user.\")\n",
    "    else:\n",
    "        print(f\"The output path {config['output_path']} does not exist. Proceeding...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(gt,pred):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(gt,label=\"true\")  \n",
    "    ax.plot(gt,label=\"pred\")\n",
    "    ax.legend()\n",
    "    return fig\n",
    "def log_img(gt,pred):\n",
    "    gt, pred = gt[0].detach().clone().cpu().numpy(), pred[0].detach().clone().cpu().numpy()\n",
    "    figure = create_figure(gt,pred)\n",
    "    img = wandb.Image(figure)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    return img\n",
    "def compute_class_weights(labels):\n",
    "# クラスごとのサンプル数をカウント\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    total_samples = len(labels)\n",
    "    \n",
    "    # クラスの重みを計算 (サンプル数の逆数で重み付け)\n",
    "    weights = total_samples / (len(unique) * counts)\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "# モデルの評価指標\n",
    "def calculate_metrics(y_true, y_pred,classes=2):\n",
    "    # 正解率\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    \n",
    "    # クラスごとの精度を計算\n",
    "    class_accuracies = []\n",
    "    for cls in range(classes):\n",
    "        mask = (y_true == cls)\n",
    "        if np.sum(mask) > 0:\n",
    "            class_acc = np.sum((y_true == y_pred) & mask) / np.sum(mask)\n",
    "            class_accuracies.append(class_acc)\n",
    "        else:\n",
    "            raise ValueError(f\"Class {cls} has no samples.\")\n",
    "    \n",
    "    # マクロ平均F1スコア\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    return accuracy, class_accuracies, f1_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789134, 1, 1250) (789134,)\n",
      "torch.Size([789134, 1, 1250]) torch.Size([789134])\n",
      "torch.Size([98148, 1, 1250]) torch.Size([98148])\n",
      "Training data:\n",
      "x shape: torch.Size([1, 1250]), x dtype: torch.float32\n",
      "y shape: torch.Size([]), y dtype: torch.int64\n",
      "Unique labels in training: tensor([0, 1])\n",
      "\n",
      "Test data:\n",
      "x shape: torch.Size([1, 1250]), x dtype: torch.float32\n",
      "y shape: torch.Size([]), y dtype: torch.int64\n",
      "Unique labels in test: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "# データセットとDataLoaderの作成\n",
    "data_dir = '../../data/processed/BP_npy/PulseDB'\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = BPDataset(data_dir,train=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = BPDataset(data_dir,train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# トレーニングデータの確認\n",
    "x, y = train_dataset[0]\n",
    "print(\"Training data:\")\n",
    "print(f\"x shape: {x.shape}, x dtype: {x.dtype}\")\n",
    "print(f\"y shape: {y.shape}, y dtype: {y.dtype}\")\n",
    "print(f\"Unique labels in training: {torch.unique(train_dataset.y)}\")\n",
    "\n",
    "# テストデータの確認\n",
    "x, y = test_dataset[0]\n",
    "print(\"\\nTest data:\")\n",
    "print(f\"x shape: {x.shape}, x dtype: {x.dtype}\")\n",
    "print(f\"y shape: {y.shape}, y dtype: {y.dtype}\")\n",
    "print(f\"Unique labels in test: {torch.unique(test_dataset.y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([61297, 36851]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet1d import ResNet1D\n",
    "from se_resnet1d import resnet18mini2\n",
    "def train_model(config):\n",
    "    \n",
    "    # Initialize Weights & Biases (wandb)\n",
    "    wandb.init(project=\"regression-training\", config=config)\n",
    "    config = wandb.config\n",
    "\n",
    "    # Dataset and DataLoader\n",
    "    # train_dataset = train_dataset(data_root=r\"..\\data\\processed\\BP_npy\\250107_1152\\p00\")\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    train_loader = train_dataloader\n",
    "    # val_dataset = test_dataset(data_len=-1,data_root=r\"..\\data\\processed\\BP_npy\\250107_1152\\p00\")\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    val_loader = test_dataloader\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\",device)\n",
    "    labels = train_dataset.y.numpy()\n",
    "    class_weights = compute_class_weights(labels)\n",
    "    print(class_weights)\n",
    "    class_weights = class_weights.to(device)  # 重みをGPUに移動\n",
    "\n",
    "    # Model, Loss, and Optimizer\n",
    "    # model = ResNet1D(**config[\"network\"])\n",
    "    model = resnet18mini2(num_classes=config[\"network\"][\"n_classes\"],in_channels=1)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # mae = nn.L1Loss()  # Mean Squared Error Loss for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    earlystopping = EarlyStopping(f\"{config.output_path}/best.pth\",config.patience,verbose=True)\n",
    "    model.to(device)\n",
    "\n",
    "    wandb.watch(model, log_freq=config.log_interval)\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # running_loss_mae = 0.0\n",
    "        # Training phase with progress bar\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Training\", leave=False)\n",
    "        for batch_idx, (x,y) in enumerate(train_loader_tqdm):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            # print(gt.shape,cond.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            # print(outputs.device,y.device)\n",
    "            loss = criterion(outputs, y)\n",
    "            # loss_mae = mae(outputs, gt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % config.log_interval == 0:\n",
    "                wandb.log({\"train_loss_step\": loss.item()})\n",
    "            # if batch_idx  == 0:\n",
    "                # wandb.log({\"train/loss\": log_img(gt,outputs)})\n",
    "            running_loss += loss.item()\n",
    "            # running_loss_mae += loss_mae.item()\n",
    "            train_loader_tqdm.set_postfix(loss=running_loss/(batch_idx+1))\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # train_loss_mae = running_loss_mae / len(train_loader)\n",
    "\n",
    "        # Validation phase with progress bar\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Validation\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x,y) in enumerate(val_loader_tqdm):\n",
    "\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                # loss_mae = mae(outputs, gt)\n",
    "                if batch_idx % config.log_interval == 0:\n",
    "                    wandb.log({\"test_loss_step\": loss.item()})\n",
    "                # if batch_idx  == 0:\n",
    "                #     wandb.log({\"val/loss\": log_img(gt,outputs)})\n",
    "                val_loss += loss.item()\n",
    "                # val_loss_mae += loss_mae.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                all_y_true.extend(y.cpu().numpy())\n",
    "                all_y_pred.extend(predicted.cpu().numpy())\n",
    "        all_y_true = np.array(all_y_true)\n",
    "        all_y_pred = np.array(all_y_pred)\n",
    "        accuracy, class_accuracies, f1 = calculate_metrics(all_y_true, all_y_pred,classes=config[\"network\"][\"n_classes\"])\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        # WandBでのログ記録例\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"test_loss\": val_loss,\n",
    "            \"accuracy\": accuracy.item(),\n",
    "            \"f1_macro\": f1,\n",
    "            \"class_0_accuracy\": class_accuracies[0].item(),\n",
    "            \"class_1_accuracy\": class_accuracies[1].item(),\n",
    "            # \"class_2_accuracy\": class_accuracies[2].item(),\n",
    "            # \"class_3_accuracy\": class_accuracies[3].item(),\n",
    "            \"conf_mat\": wandb.plot.confusion_matrix(y_true=all_y_true, preds=all_y_pred, class_names=[\"0\",\"1\"]),\n",
    "            \"epoch\": epoch + 1\n",
    "        })\n",
    "        # val_loss_mae /= len(val_loader)\n",
    "        earlystopping(val_loss,model)\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early Stopping!\")\n",
    "            wandb.finish()\n",
    "            break\n",
    "        # Log metrics to wandb\n",
    "        # wandb.log({\n",
    "        #     \"epoch\": epoch + 1,\n",
    "        #     \"train/loss_epoch\": train_loss,\n",
    "        #     \"train/mae\": train_loss_mae,\n",
    "        #     \"val/loss_epoch\": val_loss,\n",
    "        #     \"val/mae\": val_loss_mae\n",
    "        # })\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}]\"\n",
    "              f\" Train Loss: {train_loss:.4f}\"\n",
    "              f\" Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from se_resnet1d import resnet18mini as resnet\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "def train_model_clf_cv(config,fold=5):\n",
    "    output_warning(config)\n",
    "    data_dir = '../../data/processed/BP_npy/PulseDB'\n",
    "    # Initialize Weights & Biases (wandb)\n",
    "    wandb.init(project=\"regression-training\", config=config)\n",
    "    config = wandb.config\n",
    "    \n",
    "    for f in range(fold):\n",
    "        \n",
    "        train_dataset = BPDataset(data_dir,cv=True,fold=f,train=True)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "        val_dataset = BPDataset(data_dir,cv=True,fold=f,train=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"device:\",device)\n",
    "        unique, counts = np.unique(train_dataset.y, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            print(f\"ラベル {label}: {count}件\")\n",
    "        unique, counts = np.unique(val_dataset.y, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            print(f\"ラベル {label}: {count}件\")\n",
    "        # Model, Loss, and Optimizer\n",
    "        # model = ResNet1D(**config[\"network\"])\n",
    "        model = resnet(num_classes=config[\"network\"][\"n_classes\"],in_channels=1)\n",
    "        # criterion = nn.L1Loss()\n",
    "        labels = np.load(f'{data_dir}/train_sbp_2labels.npy')\n",
    "        with open(f\"{data_dir}/cv_5fold_2labels.pkl\", \"rb\") as file:\n",
    "            cv_idx = pickle.load(file) \n",
    "            labels = labels[cv_idx[0][f]]\n",
    "        class_weights = compute_class_weights(labels)\n",
    "        print(class_weights)\n",
    "        class_weights = class_weights.to(device)  # 重みをGPUに移動\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        # mae = nn.L1Loss()  # Mean Squared Error Loss for regression\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        total_step_size = len(train_loader) * config.min_epochs\n",
    "        warmup_steps = int(total_step_size * 0.1)  # 10% of total steps\n",
    "        lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_step_size)\n",
    "\n",
    "        earlystopping = EarlyStopping(f\"{config.output_path}/best_fold{f}.pth\",config.patience,verbose=True)\n",
    "        model.to(device)\n",
    "\n",
    "        wandb.watch(model, log_freq=config.log_interval)\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            # running_loss_mae = 0.0\n",
    "            # Training phase with progress bar\n",
    "            train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Training\", leave=False)\n",
    "            for batch_idx, (x,y) in enumerate(train_loader_tqdm):\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                # print(gt.shape,cond.shape)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x)\n",
    "                # print(\"Input shape:\", x.shape,y.shape,outputs.shape)\n",
    "                # print(\"Check for NaN:\", torch.isnan(x).any(),torch.isnan(y).any(),torch.isnan(outputs).any())\n",
    "                # print(\"Check for Inf:\", torch.isinf(x).any(),torch.isinf(y).any(),torch.isinf(outputs).any())\n",
    "                # print(outputs.device,y.device)\n",
    "                loss = criterion(outputs, y) \n",
    "                # loss_mae = mae(outputs, gt)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                if batch_idx % config.log_interval == 0:\n",
    "                    wandb.log({\"train_loss_step\": loss.item(),\n",
    "                               \"lr\": lr_scheduler.get_last_lr()[0]})\n",
    "                # if batch_idx  == 0:\n",
    "                    # wandb.log({\"train/loss\": log_img(gt,outputs)})\n",
    "                running_loss += loss.item()\n",
    "                # running_loss_mae += loss_mae.item()\n",
    "                train_loader_tqdm.set_postfix(loss=running_loss/(batch_idx+1))\n",
    "\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            # train_loss_mae = running_loss_mae / len(train_loader)\n",
    "\n",
    "            # Validation phase with progress bar\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_y_true = []\n",
    "            all_y_pred = []\n",
    "            val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Validation\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (x,y) in enumerate(val_loader_tqdm):\n",
    "\n",
    "                    x,y = x.to(device), y.to(device)\n",
    "                    outputs = model(x)\n",
    "                    # print(outputs.device,y.device)\n",
    "                    loss = criterion(outputs,y) \n",
    "                    # loss_mae = mae(outputs, gt)\n",
    "                    if batch_idx % config.log_interval == 0:\n",
    "                        wandb.log({\"test_loss_step\": loss.item()})\n",
    "                    # if batch_idx  == 0:\n",
    "                    #     wandb.log({\"val/loss\": log_img(gt,outputs)})\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    # val_loss_mae += loss_mae.item()\n",
    "                    all_y_true.extend(np.array(y.cpu().numpy()))\n",
    "                    all_y_pred.extend(np.array(predicted.cpu().numpy()))\n",
    "            all_y_true = np.array(all_y_true)\n",
    "            all_y_pred = np.array(all_y_pred)\n",
    "            # print(all_y_true.shape,all_y_pred.shape)\n",
    "            accuracy, class_accuracies, f1 = calculate_metrics(all_y_true, all_y_pred,classes=config[\"network\"][\"n_classes\"])\n",
    "            # error = (all_y_true - all_y_pred)\n",
    "            # mse = np.mean(error**2,axis=0)\n",
    "            # rmse = np.sqrt(mse)\n",
    "            # std = np.std(error,axis=0)\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            # WandBでのログ記録例\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"test_loss\": val_loss,\n",
    "                \"accuracy\": accuracy.item(),\n",
    "                \"f1_macro\": f1,\n",
    "                \"conf_mat\": wandb.plot.confusion_matrix(y_true=all_y_true, preds=all_y_pred, class_names=[\"0\",\"1\"]),\n",
    "                \"epoch\": epoch + 1\n",
    "            })\n",
    "            # val_loss /= len(val_loader)\n",
    "            # val_loss_mae /= len(val_loader)\n",
    "            earlystopping(val_loss,model)\n",
    "            if earlystopping.early_stop:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "            # Log metrics to wandb\n",
    "            # wandb.log({\n",
    "            #     \"epoch\": epoch + 1,\n",
    "            #     \"train/loss_epoch\": train_loss,\n",
    "            #     \"train/mae\": train_loss_mae,\n",
    "            #     \"val/loss_epoch\": val_loss,\n",
    "            #     \"val/mae\": val_loss_mae\n",
    "            # })\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{config.epochs}]\"\n",
    "                f\" Train Loss: {train_loss:.4f}\"\n",
    "                f\" Val Loss: {val_loss:.4f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(45.722222222222214, 0.5, 'True Label')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm = [[39559,  21738],\n",
    "      [12403,  24448]]\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NT',\"PHT\"], yticklabels=['NT', 'PHT'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"network\":{\n",
    "        \"in_channels\":1,\n",
    "        \"base_filters\":64,\n",
    "        \"kernel_size\":3,\n",
    "        \"stride\":1,\n",
    "        \"groups\":1,\n",
    "        \"n_block\":5,\n",
    "        \"n_classes\":2,\n",
    "        \"dropout\":0.5,\n",
    "    },\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\":100,\n",
    "    \"min_epochs\":15,\n",
    "    \"log_interval\":100,\n",
    "    \"input_shape\":[1,1250],\n",
    "    \"output_path\": \"..\\\\outputs\\\\resnet\\\\aaaa\",\n",
    "    \"patience\":5    \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from se_resnet1d import resnet18mini as resnet\n",
    "model = resnet(num_classes=config[\"network\"][\"n_classes\"],in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet1D_Small                           [16, 2]                   --\n",
       "├─Conv1d: 1-1                            [16, 32, 597]             2,048\n",
       "├─BatchNorm1d: 1-2                       [16, 32, 597]             64\n",
       "├─ReLU: 1-3                              [16, 32, 597]             --\n",
       "├─MaxPool1d: 1-4                         [16, 32, 299]             --\n",
       "├─Sequential: 1-5                        [16, 32, 299]             --\n",
       "│    └─BasicBlock2: 2-1                  [16, 32, 299]             --\n",
       "│    │    └─Conv1d: 3-1                  [16, 32, 299]             5,120\n",
       "│    │    └─BatchNorm1d: 3-2             [16, 32, 299]             64\n",
       "│    │    └─ReLU: 3-3                    [16, 32, 299]             --\n",
       "│    │    └─Conv1d: 3-4                  [16, 32, 299]             5,120\n",
       "│    │    └─BatchNorm1d: 3-5             [16, 32, 299]             64\n",
       "│    │    └─ReLU: 3-6                    [16, 32, 299]             --\n",
       "│    └─BasicBlock2: 2-2                  [16, 32, 299]             --\n",
       "│    │    └─Conv1d: 3-7                  [16, 32, 299]             5,120\n",
       "│    │    └─BatchNorm1d: 3-8             [16, 32, 299]             64\n",
       "│    │    └─ReLU: 3-9                    [16, 32, 299]             --\n",
       "│    │    └─Conv1d: 3-10                 [16, 32, 299]             5,120\n",
       "│    │    └─BatchNorm1d: 3-11            [16, 32, 299]             64\n",
       "│    │    └─ReLU: 3-12                   [16, 32, 299]             --\n",
       "├─Sequential: 1-6                        [16, 32, 150]             --\n",
       "│    └─BasicBlock2: 2-3                  [16, 32, 150]             --\n",
       "│    │    └─Conv1d: 3-13                 [16, 32, 150]             5,120\n",
       "│    │    └─BatchNorm1d: 3-14            [16, 32, 150]             64\n",
       "│    │    └─ReLU: 3-15                   [16, 32, 150]             --\n",
       "│    │    └─Conv1d: 3-16                 [16, 32, 150]             5,120\n",
       "│    │    └─BatchNorm1d: 3-17            [16, 32, 150]             64\n",
       "│    │    └─Sequential: 3-18             [16, 32, 150]             1,088\n",
       "│    │    └─ReLU: 3-19                   [16, 32, 150]             --\n",
       "│    └─BasicBlock2: 2-4                  [16, 32, 150]             --\n",
       "│    │    └─Conv1d: 3-20                 [16, 32, 150]             5,120\n",
       "│    │    └─BatchNorm1d: 3-21            [16, 32, 150]             64\n",
       "│    │    └─ReLU: 3-22                   [16, 32, 150]             --\n",
       "│    │    └─Conv1d: 3-23                 [16, 32, 150]             5,120\n",
       "│    │    └─BatchNorm1d: 3-24            [16, 32, 150]             64\n",
       "│    │    └─ReLU: 3-25                   [16, 32, 150]             --\n",
       "├─Sequential: 1-7                        [16, 64, 75]              --\n",
       "│    └─BasicBlock2: 2-5                  [16, 64, 75]              --\n",
       "│    │    └─Conv1d: 3-26                 [16, 64, 75]              10,240\n",
       "│    │    └─BatchNorm1d: 3-27            [16, 64, 75]              128\n",
       "│    │    └─ReLU: 3-28                   [16, 64, 75]              --\n",
       "│    │    └─Conv1d: 3-29                 [16, 64, 75]              20,480\n",
       "│    │    └─BatchNorm1d: 3-30            [16, 64, 75]              128\n",
       "│    │    └─Sequential: 3-31             [16, 64, 75]              2,176\n",
       "│    │    └─ReLU: 3-32                   [16, 64, 75]              --\n",
       "│    └─BasicBlock2: 2-6                  [16, 64, 75]              --\n",
       "│    │    └─Conv1d: 3-33                 [16, 64, 75]              20,480\n",
       "│    │    └─BatchNorm1d: 3-34            [16, 64, 75]              128\n",
       "│    │    └─ReLU: 3-35                   [16, 64, 75]              --\n",
       "│    │    └─Conv1d: 3-36                 [16, 64, 75]              20,480\n",
       "│    │    └─BatchNorm1d: 3-37            [16, 64, 75]              128\n",
       "│    │    └─ReLU: 3-38                   [16, 64, 75]              --\n",
       "├─Sequential: 1-8                        [16, 64, 38]              --\n",
       "│    └─BasicBlock2: 2-7                  [16, 64, 38]              --\n",
       "│    │    └─Conv1d: 3-39                 [16, 64, 38]              20,480\n",
       "│    │    └─BatchNorm1d: 3-40            [16, 64, 38]              128\n",
       "│    │    └─ReLU: 3-41                   [16, 64, 38]              --\n",
       "│    │    └─Conv1d: 3-42                 [16, 64, 38]              20,480\n",
       "│    │    └─BatchNorm1d: 3-43            [16, 64, 38]              128\n",
       "│    │    └─Sequential: 3-44             [16, 64, 38]              4,224\n",
       "│    │    └─ReLU: 3-45                   [16, 64, 38]              --\n",
       "│    └─BasicBlock2: 2-8                  [16, 64, 38]              --\n",
       "│    │    └─Conv1d: 3-46                 [16, 64, 38]              20,480\n",
       "│    │    └─BatchNorm1d: 3-47            [16, 64, 38]              128\n",
       "│    │    └─ReLU: 3-48                   [16, 64, 38]              --\n",
       "│    │    └─Conv1d: 3-49                 [16, 64, 38]              20,480\n",
       "│    │    └─BatchNorm1d: 3-50            [16, 64, 38]              128\n",
       "│    │    └─ReLU: 3-51                   [16, 64, 38]              --\n",
       "├─AdaptiveAvgPool1d: 1-9                 [16, 64, 1]               --\n",
       "├─Dropout: 1-10                          [16, 64]                  --\n",
       "├─Linear: 1-11                           [16, 2]                   130\n",
       "==========================================================================================\n",
       "Total params: 205,826\n",
       "Trainable params: 205,826\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 309.95\n",
       "==========================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 30.09\n",
       "Params size (MB): 0.82\n",
       "Estimated Total Size (MB): 30.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (16,1, 1250), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([ 13327, 298046]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0, 1]), tensor([502775, 286359])),\n",
       " (tensor([0, 1]), tensor([61297, 36851])))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.unique(return_counts=True),test_dataset.y.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yumcy9r6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2713766b8697494182fe4e1509891307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.17769114688128773, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss_step</td><td>███▃▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss_step</td><td>0.66054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-bird-169</strong> at: <a href='https://wandb.ai/bsa_mh/regression-training/runs/yumcy9r6' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/yumcy9r6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251205_211810-yumcy9r6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yumcy9r6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\minowa\\BloodPressureEstimation\\notebooks\\BP_regression\\wandb\\run-20251205_213856-1bka3wo4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bsa_mh/regression-training/runs/1bka3wo4' target=\"_blank\">pious-resonance-170</a></strong> to <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bsa_mh/regression-training/runs/1bka3wo4' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/1bka3wo4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "tensor([0.7848, 1.3779])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.61199 --> 0.61199).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.6117 Val Loss: 0.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.61199\n",
      "Epoch [2/100] Train Loss: 0.5806 Val Loss: 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# loss_mae = mae(outputs, gt)\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output path ..\\outputs\\resnet\\0415_2class_cv_res18mini4 does not exist. Proceeding...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\minowa\\BloodPressureEstimation\\notebooks\\BP_regression\\wandb\\run-20250415_152300-t3fekk19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bsa_mh/regression-training/runs/t3fekk19' target=\"_blank\">wild-fog-165</a></strong> to <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bsa_mh/regression-training/runs/t3fekk19' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/t3fekk19</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249952, 1, 1250) (249952,)\n",
      "torch.Size([249952, 1, 1250]) torch.Size([249952])\n",
      "torch.Size([62488, 1, 1250]) torch.Size([62488])\n",
      "device: cuda\n",
      "ラベル 0: 137792件\n",
      "ラベル 1: 112160件\n",
      "ラベル 0: 33988件\n",
      "ラベル 1: 28500件\n",
      "tensor([0.9070, 1.1143])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.47124 --> 0.47124).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.5622 Val Loss: 0.4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.47124\n",
      "Epoch [2/100] Train Loss: 0.4116 Val Loss: 0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "the best of loss: 0.47124\n",
      "Epoch [3/100] Train Loss: 0.3716 Val Loss: 0.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "the best of loss: 0.47124\n",
      "Epoch [4/100] Train Loss: 0.3465 Val Loss: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "the best of loss: 0.47124\n",
      "Epoch [5/100] Train Loss: 0.3260 Val Loss: 0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "the best of loss: 0.47124\n",
      "Early Stopping!\n",
      "(249952, 1, 1250) (249952,)\n",
      "torch.Size([249952, 1, 1250]) torch.Size([249952])\n",
      "torch.Size([62488, 1, 1250]) torch.Size([62488])\n",
      "device: cuda\n",
      "ラベル 0: 136341件\n",
      "ラベル 1: 113611件\n",
      "ラベル 0: 35439件\n",
      "ラベル 1: 27049件\n",
      "tensor([0.9166, 1.1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.52318 --> 0.52318).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.5297 Val Loss: 0.5232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.52318 --> 0.49076).  Saving model ...\n",
      "Epoch [2/100] Train Loss: 0.4073 Val Loss: 0.4908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.49076 --> 0.48661).  Saving model ...\n",
      "Epoch [3/100] Train Loss: 0.3688 Val Loss: 0.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.48661\n",
      "Epoch [4/100] Train Loss: 0.3441 Val Loss: 0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "the best of loss: 0.48661\n",
      "Epoch [5/100] Train Loss: 0.3237 Val Loss: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "the best of loss: 0.48661\n",
      "Epoch [6/100] Train Loss: 0.3063 Val Loss: 0.5435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "the best of loss: 0.48661\n",
      "Epoch [7/100] Train Loss: 0.2912 Val Loss: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "the best of loss: 0.48661\n",
      "Early Stopping!\n",
      "(249952, 1, 1250) (249952,)\n",
      "torch.Size([249952, 1, 1250]) torch.Size([249952])\n",
      "torch.Size([62488, 1, 1250]) torch.Size([62488])\n",
      "device: cuda\n",
      "ラベル 0: 137503件\n",
      "ラベル 1: 112449件\n",
      "ラベル 0: 34277件\n",
      "ラベル 1: 28211件\n",
      "tensor([0.9089, 1.1114])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.44217 --> 0.44217).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.5597 Val Loss: 0.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.44217\n",
      "Epoch [2/100] Train Loss: 0.4080 Val Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.44217 --> 0.43367).  Saving model ...\n",
      "Epoch [3/100] Train Loss: 0.3678 Val Loss: 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.43367 --> 0.41791).  Saving model ...\n",
      "Epoch [4/100] Train Loss: 0.3401 Val Loss: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.41791\n",
      "Epoch [5/100] Train Loss: 0.3192 Val Loss: 0.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "the best of loss: 0.41791\n",
      "Epoch [6/100] Train Loss: 0.3003 Val Loss: 0.4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "the best of loss: 0.41791\n",
      "Epoch [7/100] Train Loss: 0.2832 Val Loss: 0.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "the best of loss: 0.41791\n",
      "Epoch [8/100] Train Loss: 0.2679 Val Loss: 0.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "the best of loss: 0.41791\n",
      "Early Stopping!\n",
      "(249952, 1, 1250) (249952,)\n",
      "torch.Size([249952, 1, 1250]) torch.Size([249952])\n",
      "torch.Size([62488, 1, 1250]) torch.Size([62488])\n",
      "device: cuda\n",
      "ラベル 0: 137339件\n",
      "ラベル 1: 112613件\n",
      "ラベル 0: 34441件\n",
      "ラベル 1: 28047件\n",
      "tensor([0.9100, 1.1098])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.48777 --> 0.48777).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.5490 Val Loss: 0.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.48777\n",
      "Epoch [2/100] Train Loss: 0.4061 Val Loss: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "the best of loss: 0.48777\n",
      "Epoch [3/100] Train Loss: 0.3652 Val Loss: 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "the best of loss: 0.48777\n",
      "Epoch [4/100] Train Loss: 0.3384 Val Loss: 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "the best of loss: 0.48777\n",
      "Epoch [5/100] Train Loss: 0.3153 Val Loss: 0.5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "the best of loss: 0.48777\n",
      "Early Stopping!\n",
      "(249952, 1, 1250) (249952,)\n",
      "torch.Size([249952, 1, 1250]) torch.Size([249952])\n",
      "torch.Size([62488, 1, 1250]) torch.Size([62488])\n",
      "device: cuda\n",
      "ラベル 0: 138145件\n",
      "ラベル 1: 111807件\n",
      "ラベル 0: 33635件\n",
      "ラベル 1: 28853件\n",
      "tensor([0.9047, 1.1178])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.54128 --> 0.54128).  Saving model ...\n",
      "Epoch [1/100] Train Loss: 0.5143 Val Loss: 0.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.54128 --> 0.49782).  Saving model ...\n",
      "Epoch [2/100] Train Loss: 0.3992 Val Loss: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "the best of loss: 0.49782\n",
      "Epoch [3/100] Train Loss: 0.3631 Val Loss: 0.5343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "the best of loss: 0.49782\n",
      "Epoch [4/100] Train Loss: 0.3362 Val Loss: 0.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "the best of loss: 0.49782\n",
      "Epoch [5/100] Train Loss: 0.3165 Val Loss: 0.5647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "the best of loss: 0.49782\n",
      "Epoch [6/100] Train Loss: 0.2984 Val Loss: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "the best of loss: 0.49782\n",
      "Early Stopping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8395204e0db1407296a86f85675cfd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.026 MB of 0.026 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▄▅▃▄▅▆▂▅▅▅▅▄▄▄▆▆▇█▇▇▇▆▇▄▁▆▆▄▄▂▄▃▃▃▄▄</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▅▁▂▃▄▅▅▆▇▁▂▃▄▅▅▆▇█▁▂▃▄▅▅▁▂▃▄▅▅▆</td></tr><tr><td>f1_macro</td><td>▄▅▂▄▅▆▂▅▅▅▅▃▄▄▆▆▇█▇▇▇▆▇▄▁▆▆▅▄▁▄▄▄▄▄▄</td></tr><tr><td>lr</td><td>▂▆██▇▇▆▂███▇▇▆▅▄▄███▇▇▆▅▄▁▅██▇▇▆▃▇██▇▇▆▅</td></tr><tr><td>test_loss</td><td>▃▄▇▅▅▄▆▄▄▄▅▇██▂▃▂▁▂▂▃▅▅▄█▅▄▇▇▇▅▆▇█▆█</td></tr><tr><td>test_loss_step</td><td>▃▃▁▂▁▂▂▂█▂▂▂▂▁▇▁▆▁▃▂▃▁▄▁▁▂▂▂▂▂▃▃▃▃▂▂▂▂▁▂</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▇▄▄▃▃▂▂▁█▄▄▃▂▂▂▁▁█▄▄▃▂▂▇▄▃▃▂▂▂</td></tr><tr><td>train_loss_step</td><td>▆▄▂▂▂▂▂▅▃▃▃▂▂▃▃▂▆▄▂▄▄▃▃▁▁█▅▃▂▁▃▁▅▂▁▄▃▅▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.77149</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>f1_macro</td><td>0.769</td></tr><tr><td>lr</td><td>6e-05</td></tr><tr><td>test_loss</td><td>0.56396</td></tr><tr><td>test_loss_step</td><td>0.21045</td></tr><tr><td>train_loss</td><td>0.28211</td></tr><tr><td>train_loss_step</td><td>0.43991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-fog-165</strong> at: <a href='https://wandb.ai/bsa_mh/regression-training/runs/t3fekk19' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/t3fekk19</a><br/>Synced 5 W&B file(s), 36 media file(s), 36 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250415_152300-t3fekk19\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_clf_cv(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n        torchao not installed.\n        Please follow the instructions at https://pytorch.org/torchtune/main/install.html#pre-requisites\n        to install torchao.\n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchtune\\__init__.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchao\\__init__.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping import of cpp extensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     autoquant,\n\u001b[0;32m     43\u001b[0m     quantize_,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes, optim, testing\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchao\\quantization\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     int_scaled_matmul,\n\u001b[0;32m      3\u001b[0m     safe_int_mm,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoquant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     ALL_AUTOQUANT_CLASS_LIST,\n\u001b[0;32m      8\u001b[0m     DEFAULT_AUTOQUANT_CLASS_LIST,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     autoquant,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchao\\kernel\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbsr_triton_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bsr_dense_addmm\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintmm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m int_scaled_matmul, safe_int_mm\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchao\\kernel\\bsr_triton_ops.py:28\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_triton_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     broadcast_batch_dims,\n\u001b[0;32m     23\u001b[0m     launch_kernel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     tile_to_blocksize,\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_triton_ops_meta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_meta, minimize, update\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_triton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_triton\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.sparse._triton_ops_meta'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cosine_schedule_with_warmup\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model_regr_cv\u001b[39m(model,config,fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      3\u001b[0m     output_warning(config)\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\torchtune\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m        torchao not installed.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m        Please follow the instructions at https://pytorch.org/torchtune/main/install.html#pre-requisites\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m        to install torchao.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Enables faster downloading. For more info: https://huggingface.co/docs/huggingface_hub/en/guides/download#faster-downloads\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# To disable, run `HF_HUB_ENABLE_HF_TRANSFER=0 tune download <model_config>`\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \n        torchao not installed.\n        Please follow the instructions at https://pytorch.org/torchtune/main/install.html#pre-requisites\n        to install torchao.\n        "
     ]
    }
   ],
   "source": [
    "from torchtune.modules import get_cosine_schedule_with_warmup\n",
    "def train_model_regr_cv(model,config,fold=5):\n",
    "    output_warning(config)\n",
    "    data_dir = '../../data/processed/BP_npy/PulseDB'\n",
    "    cv_idx_path = r\"../../data/processed/BP_npy/PulseDB/cv_5fold.pkl\"\n",
    "    with open(cv_idx_path, \"rb\") as f:\n",
    "        cv_idx = pickle.load(f)\n",
    "    # Initialize Weights & Biases (wandb)\n",
    "    wandb.init(project=\"regression-training\", config=config)\n",
    "    config = wandb.config\n",
    "    \n",
    "    for f in range(fold):\n",
    "        \n",
    "        train_dataset = BPDataset_Regr(data_dir,cv=cv_idx[0][f],train=True)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        val_dataset = BPDataset_Regr(data_dir,cv=cv_idx[1][f],train=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"device:\",device)\n",
    "\n",
    "        # Model, Loss, and Optimizer\n",
    "        criterion = nn.L1Loss()\n",
    "        # criterion = nn.CrossEntropyLoss()\n",
    "        # mae = nn.L1Loss()  # Mean Squared Error Loss for regression\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        total_step_size = len(train_loader) * config.epochs\n",
    "        warmup_steps = int(total_step_size * 0.1)  # 10% of total steps\n",
    "        lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_step_size)\n",
    "        earlystopping = EarlyStopping(f\"{config.output_path}/best_fold{f}.pth\",config.patience,verbose=True)\n",
    "        model.to(device)\n",
    "\n",
    "        wandb.watch(model, log_freq=config.log_interval)\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            # running_loss_mae = 0.0\n",
    "            # Training phase with progress bar\n",
    "            train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Training\", leave=False)\n",
    "            for batch_idx, (x,sbp,dbp) in enumerate(train_loader_tqdm):\n",
    "                x,sbp,dbp = x.to(device), sbp.to(device),dbp.to(device)\n",
    "                # print(gt.shape,cond.shape)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x)\n",
    "                # print(outputs.device,y.device)\n",
    "                loss_sbp = criterion(outputs[:,0], sbp) \n",
    "                loss_dbp = criterion(outputs[:,1], dbp)\n",
    "                loss = loss_sbp + loss_dbp\n",
    "                # loss_mae = mae(outputs, gt)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                if batch_idx % config.log_interval == 0:\n",
    "                    wandb.log({\"train_loss_step\": loss.item()})\n",
    "                # if batch_idx  == 0:\n",
    "                    # wandb.log({\"train/loss\": log_img(gt,outputs)})\n",
    "                running_loss += loss.item()\n",
    "                # running_loss_mae += loss_mae.item()\n",
    "                train_loader_tqdm.set_postfix(loss=running_loss/(batch_idx+1))\n",
    "\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            # train_loss_mae = running_loss_mae / len(train_loader)\n",
    "\n",
    "            # Validation phase with progress bar\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_y_true = []\n",
    "            all_y_pred = []\n",
    "            val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Validation\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (x,sbp,dbp) in enumerate(val_loader_tqdm):\n",
    "\n",
    "                    x,sbp,dbp = x.to(device), sbp.to(device),dbp.to(device)\n",
    "                    outputs = model(x)\n",
    "                    # print(outputs.device,y.device)\n",
    "                    loss_sbp = criterion(outputs[:,0], sbp) \n",
    "                    loss_dbp = criterion(outputs[:,1], dbp)\n",
    "                    loss = loss_sbp + loss_dbp\n",
    "                    # loss_mae = mae(outputs, gt)\n",
    "                    if batch_idx % config.log_interval == 0:\n",
    "                        wandb.log({\"test_loss_step\": loss.item()})\n",
    "                    # if batch_idx  == 0:\n",
    "                    #     wandb.log({\"val/loss\": log_img(gt,outputs)})\n",
    "                    val_loss += loss.item()\n",
    "                    # val_loss_mae += loss_mae.item()\n",
    "                    all_y_true.extend(np.array([sbp.cpu().numpy(),dbp.cpu().numpy()]))\n",
    "                    all_y_pred.extend(np.array([outputs[:,0].cpu().numpy(),outputs[:,1].cpu().numpy()]))\n",
    "            all_y_true = np.concatenate(all_y_true,axis=0).reshape(-1,2)\n",
    "            all_y_pred = np.concatenate(all_y_pred,axis=0).reshape(-1,2)\n",
    "            # print(all_y_true.shape,all_y_pred.shape)\n",
    "            # accuracy, class_accuracies, f1 = calculate_metrics(all_y_true, all_y_pred,classes=config[\"network\"][\"n_classes\"])\n",
    "            error = (all_y_true - all_y_pred)\n",
    "            mse = np.mean(error**2,axis=0)\n",
    "            rmse = np.sqrt(mse)\n",
    "            std = np.std(error,axis=0)\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            # WandBでのログ記録例\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"test_loss\": val_loss,\n",
    "                \"mse_sbp\": mse[0],\n",
    "                \"rmse_sbp\": rmse[0],\n",
    "                \"std_sbp\": std[0],\n",
    "                \"mse_dbp\": mse[1],\n",
    "                \"rmse_dbp\": rmse[1],\n",
    "                \"std_dbp\": std[1],\n",
    "                # \"conf_mat\": wandb.plot.confusion_matrix(y_true=all_y_true, preds=all_y_pred, class_names=[\"0\",\"1\",\"2\",\"3\"]),\n",
    "                \"epoch\": epoch + 1\n",
    "            })\n",
    "            # val_loss /= len(val_loader)\n",
    "            # val_loss_mae /= len(val_loader)\n",
    "            earlystopping(val_loss,model)\n",
    "            if earlystopping.early_stop:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "            # Log metrics to wandb\n",
    "            # wandb.log({\n",
    "            #     \"epoch\": epoch + 1,\n",
    "            #     \"train/loss_epoch\": train_loss,\n",
    "            #     \"train/mae\": train_loss_mae,\n",
    "            #     \"val/loss_epoch\": val_loss,\n",
    "            #     \"val/mae\": val_loss_mae\n",
    "            # })\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{config.epochs}]\"\n",
    "                f\" Train Loss: {train_loss:.4f}\"\n",
    "                f\" Val Loss: {val_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_regr(config):\n",
    "    \n",
    "    # Initialize Weights & Biases (wandb)\n",
    "    wandb.init(project=\"regression-training\", config=config)\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Dataset and DataLoader\n",
    "    # train_dataset = train_dataset(data_root=r\"..\\data\\processed\\BP_npy\\250107_1152\\p00\")\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    train_loader = train_dataloader\n",
    "    # val_dataset = test_dataset(data_len=-1,data_root=r\"..\\data\\processed\\BP_npy\\250107_1152\\p00\")\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    val_loader = test_dataloader\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\",device)\n",
    "\n",
    "        \n",
    "    # Model, Loss, and Optimizer\n",
    "    model = ResNet1D(**config[\"network\"])\n",
    "    criterion = nn.L1Loss()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # mae = nn.L1Loss()  # Mean Squared Error Loss for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    earlystopping = EarlyStopping(f\"{config.output_path}/best.pth\",config.patience,verbose=True)\n",
    "    model.to(device)\n",
    "\n",
    "    wandb.watch(model, log_freq=config.log_interval)\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # running_loss_mae = 0.0\n",
    "        # Training phase with progress bar\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Training\", leave=False)\n",
    "        for batch_idx, (x,sbp,dbp) in enumerate(train_loader_tqdm):\n",
    "            x,sbp,dbp = x.to(device), sbp.to(device),dbp.to(device)\n",
    "            # print(gt.shape,cond.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            # print(outputs.device,y.device)\n",
    "            loss_sbp = criterion(outputs[:,0], sbp) \n",
    "            loss_dbp = criterion(outputs[:,1], dbp)\n",
    "            loss = loss_sbp + loss_dbp\n",
    "            # loss_mae = mae(outputs, gt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % config.log_interval == 0:\n",
    "                wandb.log({\"train_loss_step\": loss.item()})\n",
    "            # if batch_idx  == 0:\n",
    "                # wandb.log({\"train/loss\": log_img(gt,outputs)})\n",
    "            running_loss += loss.item()\n",
    "            # running_loss_mae += loss_mae.item()\n",
    "            train_loader_tqdm.set_postfix(loss=running_loss/(batch_idx+1))\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # train_loss_mae = running_loss_mae / len(train_loader)\n",
    "\n",
    "        # Validation phase with progress bar\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{config.epochs} - Validation\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x,sbp,dbp) in enumerate(val_loader_tqdm):\n",
    "\n",
    "                x,sbp,dbp = x.to(device), sbp.to(device),dbp.to(device)\n",
    "                outputs = model(x)\n",
    "                # print(outputs.device,y.device)\n",
    "                loss_sbp = criterion(outputs[:,0], sbp) \n",
    "                loss_dbp = criterion(outputs[:,1], dbp)\n",
    "                loss = loss_sbp + loss_dbp\n",
    "                # loss_mae = mae(outputs, gt)\n",
    "                if batch_idx % config.log_interval == 0:\n",
    "                    wandb.log({\"test_loss_step\": loss.item()})\n",
    "                # if batch_idx  == 0:\n",
    "                #     wandb.log({\"val/loss\": log_img(gt,outputs)})\n",
    "                val_loss += loss.item()\n",
    "                # val_loss_mae += loss_mae.item()\n",
    "                all_y_true.extend(np.array([sbp.cpu().numpy(),dbp.cpu().numpy()]))\n",
    "                all_y_pred.extend(np.array([outputs[:,0].cpu().numpy(),outputs[:,1].cpu().numpy()]))\n",
    "        all_y_true = np.concatenate(all_y_true,axis=0).reshape(-1,2)\n",
    "        all_y_pred = np.concatenate(all_y_pred,axis=0).reshape(-1,2)\n",
    "        # print(all_y_true.shape,all_y_pred.shape)\n",
    "        # accuracy, class_accuracies, f1 = calculate_metrics(all_y_true, all_y_pred,classes=config[\"network\"][\"n_classes\"])\n",
    "        error = (all_y_true - all_y_pred)\n",
    "        mse = np.mean(error**2,axis=0)\n",
    "        rmse = np.sqrt(mse)\n",
    "        std = np.std(error,axis=0)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        # WandBでのログ記録例\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"test_loss\": val_loss,\n",
    "            \"mse_sbp\": mse[0],\n",
    "            \"rmse_sbp\": rmse[0],\n",
    "            \"std_sbp\": std[0],\n",
    "            \"mse_dbp\": mse[1],\n",
    "            \"rmse_dbp\": rmse[1],\n",
    "            \"std_dbp\": std[1],\n",
    "            # \"conf_mat\": wandb.plot.confusion_matrix(y_true=all_y_true, preds=all_y_pred, class_names=[\"0\",\"1\",\"2\",\"3\"]),\n",
    "            \"epoch\": epoch + 1\n",
    "        })\n",
    "        # val_loss /= len(val_loader)\n",
    "        # val_loss_mae /= len(val_loader)\n",
    "        earlystopping(val_loss,model)\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "        # Log metrics to wandb\n",
    "        # wandb.log({\n",
    "        #     \"epoch\": epoch + 1,\n",
    "        #     \"train/loss_epoch\": train_loss,\n",
    "        #     \"train/mae\": train_loss_mae,\n",
    "        #     \"val/loss_epoch\": val_loss,\n",
    "        #     \"val/mae\": val_loss_mae\n",
    "        # })\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}]\"\n",
    "              f\" Train Loss: {train_loss:.4f}\"\n",
    "              f\" Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# train_dataset = BPDataset_Regr(data_dir,train=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# トレーニングデータの確認\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m x, y1,y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# データセットとDataLoaderの作成\n",
    "data_dir = '../../data/processed/BP_npy/PulseDB'\n",
    "batch_size = 32\n",
    "\n",
    "# train_dataset = BPDataset_Regr(data_dir,train=True)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = BPDataset_Regr(data_dir,train=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# トレーニングデータの確認\n",
    "x, y1,y2 = train_dataset[0]\n",
    "print(\"Training data:\")\n",
    "print(f\"x shape: {x.shape}, x dtype: {x.dtype}\")\n",
    "print(f\"y shape: {y1.shape}, y dtype: {y1.dtype}\")\n",
    "# print(f\"Unique labels in training: {torch.unique(train_dataset.y)}\")\n",
    "\n",
    "# テストデータの確認\n",
    "x, y1,y2 = test_dataset[0]\n",
    "print(\"\\nTest data:\")\n",
    "print(f\"x shape: {x.shape}, x dtype: {x.dtype}\")\n",
    "print(f\"y shape: {y1.shape}, y dtype: {y1.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4681), tensor(0.3178))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,i,u=train_dataset[0]\n",
    "i,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: 24amj35 (bsa_mh). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"network\":{\n",
    "        \"in_channels\":1,\n",
    "        \"base_filters\":64,\n",
    "        \"kernel_size\":3,\n",
    "        \"stride\":1,\n",
    "        \"groups\":1,\n",
    "        \"n_block\":5,\n",
    "        \"n_classes\":2,\n",
    "    },\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\":100,\n",
    "    \"log_interval\":100,\n",
    "    \"input_shape\":[1,1250],\n",
    "    \"output_path\": \"..\\\\outputs\\\\resnet\\\\0308_regr\",\n",
    "    \"patience\":10    \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "cv_idx_path = r\"../../data/processed/BP_npy/PulseDB/cv_5fold.pkl\"\n",
    "with open(cv_idx_path, \"rb\") as f:\n",
    "    cv_idx = pickle.load(f)\n",
    "print(len(cv_idx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet1D(**config[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output path ..\\outputs\\resnet\\0310_trans does not exist. Proceeding...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hxnts44a) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94724431df904639ac08b2cacb112520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-leaf-88</strong> at: <a href='https://wandb.ai/bsa_mh/regression-training/runs/hxnts44a' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/hxnts44a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250310_184228-hxnts44a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hxnts44a). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610ed19daf564992a4ae7a6f969ae0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\minowa\\BloodPressureEstimation\\notebooks\\BP_regression\\wandb\\run-20250310_184317-ucnkdfft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bsa_mh/regression-training/runs/ucnkdfft' target=\"_blank\">jumping-brook-89</a></strong> to <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bsa_mh/regression-training/runs/ucnkdfft' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/ucnkdfft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model_regr_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m, in \u001b[0;36mtrain_model_regr_cv\u001b[1;34m(model, config, fold)\u001b[0m\n\u001b[0;32m      9\u001b[0m config \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fold):\n\u001b[1;32m---> 13\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBPDataset_Regr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m BPDataset_Regr(data_dir,cv\u001b[38;5;241m=\u001b[39mcv_idx[\u001b[38;5;241m1\u001b[39m][f],train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mBPDataset_Regr.__init__\u001b[1;34m(self, data_dir, cv, train)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dir,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1250\u001b[39m)  \u001b[38;5;66;03m# Shape: (-1, 1250)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msbp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train_sbp.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Shape: (-1,)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train_dbp.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Shape: (-1,)\u001b[39;00m\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mf:\\minowa\\BloodPressureEstimation\\.venv\\lib\\site-packages\\numpy\\lib\\format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model_regr_cv(model,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# best_ckpt = \".\\\\\"+config[\"output_path\"]+\"\\\\best.pth\"\n",
    "# model = ResNet1D(config, \"not\").to(device)\n",
    "# model.load_state_dict(torch.load(best_ckpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet1d import ResNet1D\n",
    "config = {\n",
    "    \"network\":{\n",
    "        \"in_channels\":1,\n",
    "        \"base_filters\":64,\n",
    "        \"kernel_size\":3,\n",
    "        \"stride\":1,\n",
    "        \"groups\":1,\n",
    "        \"n_block\":5,\n",
    "        \"n_classes\":2,\n",
    "    },\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\":100,\n",
    "    \"log_interval\":100,\n",
    "    \"input_shape\":[1,1250],\n",
    "    \"output_path\": \"..\\\\outputs\\\\resnet\\\\0310_trans\",\n",
    "    \"patience\":10    \n",
    "          }\n",
    "model = ResNet1D(**config[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('..\\\\outputs\\\\resnet\\\\0228\\\\best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layers_to_freeze = [model.first_block_conv,\n",
    "                    model.first_block_bn,\n",
    "                    model.first_block_relu,\n",
    "                    model.basicblock_list[0],\n",
    "                    model.basicblock_list[1]\n",
    "                    ]\n",
    "for layer in layers_to_freeze:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output path ..\\outputs\\resnet\\0310_trans does not exist. Proceeding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: 24amj35 (bsa_mh). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\minowa\\BloodPressureEstimation\\notebooks\\BP_regression\\wandb\\run-20250310_184228-hxnts44a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bsa_mh/regression-training/runs/hxnts44a' target=\"_blank\">polar-leaf-88</a></strong> to <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bsa_mh/regression-training' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bsa_mh/regression-training/runs/hxnts44a' target=\"_blank\">https://wandb.ai/bsa_mh/regression-training/runs/hxnts44a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model_regr_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m, in \u001b[0;36mtrain_model_regr_cv\u001b[1;34m(model, config, fold)\u001b[0m\n\u001b[0;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fold):\n\u001b[1;32m---> 12\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m BPDataset_Regr(\u001b[43mdata_dir\u001b[49m,cv\u001b[38;5;241m=\u001b[39mcv_idx[\u001b[38;5;241m0\u001b[39m][f],train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m BPDataset_Regr(data_dir,cv\u001b[38;5;241m=\u001b[39mcv_idx[\u001b[38;5;241m1\u001b[39m][f],train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "train_model_regr_cv(model,config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
